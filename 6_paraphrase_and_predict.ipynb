{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96cd09472b0592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T06:14:59.176061200Z",
     "start_time": "2024-02-16T06:14:59.161063600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from utils_paragraph import paraphrase_nlp, paraphrasing_predict_llm, paraphrase_initial, \\\n",
    "    paraphrase_seq2lan, recover_lan2seq, paraphrasing_predict_llama\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openai\n",
    "\n",
    "with open('config.json', 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "openai.api_key = config['OPENAI_API_KEY']\n",
    "openai.api_base = config['OPENAI_API_BASE']\n",
    "\n",
    "\n",
    "from data1.serialize import SerializerSettings\n",
    "from sklearn import metrics\n",
    "from models.darts import get_arima_predictions_data\n",
    "from models.llmtime import get_llmtime_predictions_data\n",
    "from data1.small_context import get_datasets, get_memorization_datasets, get_dataset\n",
    "from models.validation_likelihood_tuning import get_autotuned_predictions_data\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# load_ext autoreload\n",
    "# autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b3a230fb7994d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T06:14:59.633542200Z",
     "start_time": "2024-02-16T06:14:59.613546900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_preds(train, test, pred_dict, model_name, ds_name, show_samples=False):\n",
    "    pred = pred_dict['median']\n",
    "    pred = pd.Series(pred, index=test.index)\n",
    "    plt.figure(figsize=(8, 6), dpi=100)\n",
    "    plt.plot(train)\n",
    "    plt.plot(test, label='Truth', color='black')\n",
    "    plt.plot(pred, label=model_name, color='purple')\n",
    "    # shade 90% confidence interval\n",
    "    samples = pred_dict['samples']\n",
    "    lower = np.quantile(samples, 0.05, axis=0)\n",
    "    upper = np.quantile(samples, 0.95, axis=0)\n",
    "    plt.fill_between(pred.index, lower, upper, alpha=0.3, color='purple')\n",
    "    if show_samples:\n",
    "        samples = pred_dict['samples']\n",
    "        # convert df to numpy array\n",
    "        samples = samples.values if isinstance(samples, pd.DataFrame) else samples\n",
    "        for i in range(min(10, samples.shape[0])):\n",
    "            plt.plot(pred.index, samples[i], color='purple', alpha=0.3, linewidth=1)\n",
    "    plt.legend(loc='upper left')\n",
    "    if 'NLL/D' in pred_dict:\n",
    "        nll = pred_dict['NLL/D']\n",
    "        if nll is not None:\n",
    "            plt.text(0.03, 0.85, f'NLL/D: {nll:.2f}', transform=plt.gca().transAxes,\n",
    "                     bbox=dict(facecolor='white', alpha=0.5))\n",
    "    plt.savefig(f'{ds_name}{model_name}givenname1.pdf', format='pdf')\n",
    "\n",
    "\n",
    "def plot_preds2(train, test, pred_dict, model_name, ds_name, show_samples=False):\n",
    "    pred = pred_dict['median']\n",
    "    pred = pd.Series(pred, index=test.index)\n",
    "    plt.figure(figsize=(8, 6), dpi=100)\n",
    "    # plt.plot(train)\n",
    "    plt.plot(test, label='Truth', color='black')\n",
    "    plt.plot(pred, label=model_name, color='purple')\n",
    "    # shade 90% confidence interval\n",
    "    samples = pred_dict['samples']\n",
    "    lower = np.quantile(samples, 0.05, axis=0)\n",
    "    upper = np.quantile(samples, 0.95, axis=0)\n",
    "    plt.fill_between(pred.index, lower, upper, alpha=0.3, color='purple')\n",
    "    if show_samples:\n",
    "        samples = pred_dict['samples']\n",
    "        # convert df to numpy array\n",
    "        samples = samples.values if isinstance(samples, pd.DataFrame) else samples\n",
    "        for i in range(min(10, samples.shape[0])):\n",
    "            plt.plot(pred.index, samples[i], color='purple', alpha=0.3, linewidth=1)\n",
    "    plt.legend(loc='upper left')\n",
    "    if 'NLL/D' in pred_dict:\n",
    "        nll = pred_dict['NLL/D']\n",
    "        if nll is not None:\n",
    "            plt.text(0.03, 0.85, f'NLL/D: {nll:.2f}', transform=plt.gca().transAxes,\n",
    "                     bbox=dict(facecolor='white', alpha=0.5))\n",
    "    plt.savefig(f'{ds_name}{model_name}givenname2.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "167c8b811e892e23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T06:15:00.162580800Z",
     "start_time": "2024-02-16T06:15:00.145581100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_names: ['gpt-3.5-turbo-1106']\n"
     ]
    }
   ],
   "source": [
    "gpt4_hypers = dict(\n",
    "    alpha=0.3,\n",
    "    basic=True,\n",
    "    temp=1.0,\n",
    "    top_p=0.8,\n",
    "    settings=SerializerSettings(base=10, prec=3, signed=True, time_sep=', ', bit_sep='', minus_sign='-')\n",
    ")\n",
    "\n",
    "gpt3_hypers = dict(\n",
    "    temp=0.7,\n",
    "    alpha=0.95,\n",
    "    beta=0.3,\n",
    "    basic=False,\n",
    "    settings=SerializerSettings(base=10, prec=3, signed=True, half_bin_correction=True)\n",
    ")\n",
    "\n",
    "promptcast_hypers = dict(\n",
    "    temp=0.7,\n",
    "    settings=SerializerSettings(base=10, prec=0, signed=True,\n",
    "                                time_sep=', ',\n",
    "                                bit_sep='',\n",
    "                                plus_sign='',\n",
    "                                minus_sign='-',\n",
    "                                half_bin_correction=False,\n",
    "                                decimal_point=''))\n",
    "\n",
    "arima_hypers = dict(p=[12, 30], d=[1, 2], q=[0])\n",
    "\n",
    "model_predict_fns = {\n",
    "    'gpt-3.5-turbo-1106': get_llmtime_predictions_data,\n",
    "    # 'gpt-4-0125-preview': get_llmtime_predictions_data,\n",
    "    # 'llama2-13b-chat': get_llmtime_predictions_data,\n",
    "}\n",
    "\n",
    "model_names = list(model_predict_fns.keys())\n",
    "print(\"Model_names:\", model_names)\n",
    "\n",
    "# Initial out dict\n",
    "\n",
    "datasets_list = [\n",
    "    'AirPassengersDataset',\n",
    "    # 'AusBeerDataset',\n",
    "    # 'GasRateCO2Dataset',\n",
    "    'MonthlyMilkDataset',\n",
    "    'SunspotsDataset',\n",
    "    'WineDataset',\n",
    "    # 'WoolyDataset',\n",
    "    # 'HeartRateDataset',\n",
    "\n",
    "    # 'IstanbulTraffic',\n",
    "    # 'TSMCStock',\n",
    "    # 'TurkeyPower',\n",
    "    # 'ETTh1Dataset',\n",
    "    # 'ETTm2Dataset',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf53bd12360a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T06:16:30.934974800Z",
     "start_time": "2024-02-16T06:16:03.557229900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:  gpt-3.5-turbo-1106\n",
      "dataset_name:  AirPassengersDataset\n",
      "Round:  1\n",
      "Test_lan: 495.0,496.0,497.0,502.0,506.0,511.0,512.0,507.0,511.0,514.0,516.0,518.0,519.0,520.0,521.0,520.0,521.0,522.0,520.0,515.0,514.0,511.0,507.0,505.0,503.0,501.0,502.0,500.0,498.0,497.0,496.0,495.0,496.0,495.0,497.0,495.0,496.0,497.0,499.0,501.0,503.0,505.0,503.0,501.0,503.0,501.0,502.0,503.0,502.0,501.0,503.0,505.0\n",
      "test len: (29,)\n",
      "Seq_pred: (27,)\n",
      "Not enough sequences for prediction\n",
      "\n",
      "\n",
      "MSE: 0.0, MAE: 0.0, MAPE: 0.0, R²: 0.0\n",
      "\n",
      "\n",
      "dataset_name:  MonthlyMilkDataset\n",
      "Round:  1\n",
      "Test_lan: 706.0,724.0,668.0,629.0,675.0,694.0,673.0,751.0,771.0,835.0,807.0,763.0,719.0,680.0,682.0,648.0,692.0,708.0,665.0,767.0,787.0,851.0,822.0,778.0,734.0\n",
      "test len: (34,)\n",
      "Seq_pred: (14,)\n",
      "Not enough sequences for prediction\n",
      "\n",
      "\n",
      "MSE: 0.0, MAE: 0.0, MAPE: 0.0, R²: 0.0\n",
      "\n",
      "\n",
      "dataset_name:  SunspotsDataset\n",
      "Round:  1\n",
      "Test_lan: 57.0, 70.0, 77.0, 64.4, 50.0, 65.8, 69.3, 66.1, 57.0, 68.4, 68.4, 60.3, 58.3, 47.0, 33.9, 50.0, 21.2, 14.4, 33.0, 85.4, 106.8, 98.2, 95.9, 109.7, 89.3, 65.6, 95.7, 99.7, 104.6, 48.7, 77.3, 78.3, 70.0, 73.3, 74.3, 75.3, 96.0, 46.0, 95.3, 67.0, 56.0, 87.0, 48.3, 65.2, 74.1, 71.3, 62.4, 61.6, 68.5, 73.0, 70.0, 55.3, 56.0, 77.0, 53.0, 49.0, 31.8, 63.7, 33.2, 29.4, 14.0, 8.6, 21.3, 37.1, 47.3, 51.2, 53.2, 73.6, 37.6, 73.6, 64.7, 63.1, 77.5, 60.7, 68.4, 63.0, 27.5, 51.4, 45.2, 30.1, 48.6, 43.3, 44.8, 52.1, 24.6, 38.4, 69.2, 93.1, 77.1, 70.0, 156.0, 112.0, 92.3, 132.5, 89.9, 88.1, 127.8, 83.5, 83.5, 71.4, 73.1, 111.1, 68.5, 78.7, 67.0, 54.6, 76.4, 63.5, 65.6, 63.2, 37.7, 36.1, 73.1, 43.6, 25.6, 59.1, 33.7, 33.4, 46.6, 92.2, 50.8, 54.6, 65.4, 45.3, 52.1, 58.0, 54.0, 48.8, 45.8, 32.0, 30.2, 34.9, 26.3, 20.5, 18.8, 18.8, 18.8, 18.8, 27.2, 18.2, 22.5, 5.9, 5.3, 16.0, 24.8, 40.8, 53.5, 49.5, 57.3, 49.3, 39.3, 70.1, 68.3, 73.4, 88.8, 65.5, 85.1, 68.2, 49.3, 46.3, 74.6, 57.9, 53.4, 41.7, 39.8, 53.8, 47.2, 44.3, 55.9, 25.6, 31.6, 41.3, 30.6, 34.3, 58.5, 29.3, 42.9, 63.3, 51.5, 75.1, 83.7, 75.5, 95.5, 61.4, 76.2, 92.6, 93.9, 81.3, 78.0, 96.0, 59.7, 68.0, 69.6, 77.5, 57.5, 67.3, 67.1, 62.7, 56.2, 56.6, 38.3, 46.0, 34.5, 31.9, 23.6, 22.8, 17.6, 16.4, 22.3, 9.1, 7.9, 5.6, 2.8, 7.8, 16.0, 29.8, 44.8, 47.8, 58.1, 50.1, 47.9, 86.2, 64.1, 76.0, 115.3, 78.8, 97.3, 116.9, 107.7, 87.3, 146.7, 95.3, 89.3, 123.6, 109.3, 72.2, 112.2, 68.2, 101.0, 111.0, 75.6, 58.5, 78.3, 45.1, 35.2, 22.4, 25.4, 25.2, 25.2, 27.2, 18.3, 34.4, 14.9, 11.3, 33.3, 8.1, 43.5, 63.2, 48.2, 66.5, 72.7, 64.0, 80.5, 57.4, 65.1, 86.2, 70.1, 68.1, 85.5, 101.9, 68.7, 78.6, 84.6, 69.2, 57.6, 66.7, 60.1, 43.1, 30.3, 26.0, 25.0, 34.0, 10.0, 35.0, 65.0\n",
      "test len: (141,)\n",
      "Seq_pred: (144,)\n",
      "\n",
      "\n",
      "MSE: 5607.753333333333, MAE: 61.74751773049644, MAPE: 503.4133172146274, R²: -0.7545148138640969\n",
      "\n",
      "\n",
      "dataset_name:  WineDataset\n",
      "Round:  1\n",
      "Test_lan: 31358.0, 31358.0 increasing to 34358.0, 34358.0 decreasing to 16695.0, 16695.0 increasing to 20624.0, 20624.0 decreasing to 19109.0, 19109.0 increasing to 22740.0, 22740.0 decreasing to 19010.0, 19010.0 increasing to 19270.0, 19270.0 increasing to 20933.0, 20933.0 increasing to 24257.0, 24257.0 increasing to 29161.0, 29161.0 decreasing to 28961.0, 28961.0 increasing to 36161.0, 36161.0 decreasing to 18615.0, 18615.0 increasing to 22583.0, 22583.0 increasing to 25383.0, 25383.0 decreasing to 22183.0, 22183.0 decreasing to 20338.0, 20338.0 increasing to 29161.0, 29161.0 decreasing to 26157.0\n",
      "test len: (36,)\n",
      "Seq_pred: (21,)\n",
      "Not enough sequences for prediction\n",
      "\n",
      "\n",
      "MSE: 0.0, MAE: 0.0, MAPE: 0.0, R²: 0.0\n",
      "\n",
      "\n",
      "-------------------------New Model\n"
     ]
    }
   ],
   "source": [
    "out = {}\n",
    "datasets = get_datasets()\n",
    "num_samples = 1\n",
    "\n",
    "for model in model_names:  # GPT-4 takes a about a minute to run\n",
    "    print(\"Model name: \", model)\n",
    "    steps = 500  # predict steps\n",
    "    for dataset_name in datasets_list:\n",
    "        mse_amount = 0.0\n",
    "        mae_amount = 0.0\n",
    "        mape_amount = 0.0\n",
    "        rsquare_amount = 0.0\n",
    "        print(\"dataset_name: \", dataset_name)\n",
    "        for i in range(num_samples):\n",
    "            print(\"Round: \", i+1)\n",
    "            desp = paraphrase_initial(dataset_name)\n",
    "            data = datasets[dataset_name]\n",
    "            train, test = data\n",
    "            Train_lan = paraphrase_seq2lan(train, desp)\n",
    "            Test_lan = paraphrase_seq2lan(test, desp)\n",
    "            seq_test = recover_lan2seq(Test_lan)\n",
    "            seq_pred = paraphrasing_predict_llm(desp, Train_lan, steps, model)\n",
    "\n",
    "            print(\"test len:\", test.shape)\n",
    "            print(\"Seq_pred:\", seq_pred.shape)\n",
    "            if seq_pred.shape >= test.shape:\n",
    "                seq_pred = seq_pred[:len(test)]\n",
    "            else:\n",
    "                print(\"Not enough sequences for prediction\")\n",
    "                break\n",
    "            mse = mean_squared_error(test, seq_pred)\n",
    "            mae = mean_absolute_error(test, seq_pred)\n",
    "            mape = metrics.mean_absolute_percentage_error(test, seq_pred)*100\n",
    "            r2 = r2_score(test, seq_pred)\n",
    "\n",
    "            mse_amount += mse\n",
    "            mae_amount += mae\n",
    "            mape_amount += mape\n",
    "            rsquare_amount += r2\n",
    "\n",
    "        mse_mean = mse_amount/num_samples\n",
    "        mae_mean = mae_amount/num_samples\n",
    "        mape_mean = mape_amount/num_samples\n",
    "        r2_mean = rsquare_amount/num_samples\n",
    "    \n",
    "        # print and plot values\n",
    "        print(\"\\n\")\n",
    "        print(f'MSE: {mse_mean}, MAE: {mae_mean}, MAPE: {mape_mean}, R²: {r2_mean}')\n",
    "        print(\"\\n\")\n",
    "    print('-------------------------New Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f05ecc5c3f2ed3eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-16T06:19:17.128184200Z",
     "start_time": "2024-02-16T06:19:17.094185700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month\n",
       "1937-01-01    132.5\n",
       "1937-05-01    116.7\n",
       "1937-09-01    100.7\n",
       "1938-01-01     98.4\n",
       "1938-05-01    127.4\n",
       "              ...  \n",
       "1982-05-01     82.2\n",
       "1982-09-01    118.8\n",
       "1983-01-01     84.3\n",
       "1983-05-01     99.2\n",
       "1983-09-01     50.3\n",
       "Freq: 4MS, Name: Sunspots, Length: 141, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets[\"SunspotsDataset\"]\n",
    "train, test = data\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
