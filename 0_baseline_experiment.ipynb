{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd93fc2",
   "metadata": {},
   "source": [
    "## Experiments (baseline)\n",
    "This notebook is used for conduct the baseline prediction with the pre-trained LLMs. Adapted from [Large Language Models Are Zero Shot Time Series Forecasters\n",
    "](https://github.com/ngruver/llmtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7135a7ea",
   "metadata": {},
   "source": [
    "We predict both univariate and multivariate time series (with each prediction focusing on a single sequence). Additionally, we offer the option to apply Moving Average (MA) for smoothing the input time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb336b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries, concatenate\n",
    "from darts.utils.callbacks import TFMProgressBar\n",
    "from darts.models import NBEATSModel\n",
    "from darts.dataprocessing.transformers import Scaler, MissingValuesFiller\n",
    "from darts.metrics import mape, r2_score\n",
    "from darts.datasets import EnergyDataset\n",
    "from darts import concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from statsmodels.datasets import co2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8709f044e02e1440",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "from data1.serialize import SerializerSettings\n",
    "from data1.small_context import get_datasets,get_memorization_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00a69a9c9fffe95",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from models.utils import grid_iter\n",
    "from models.validation_likelihood_tuning import get_autotuned_predictions_data\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from models import llmtime\n",
    "from models.llmtime import get_llmtime_predictions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4900eadabd33dbd4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d096aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "\n",
    "with open(r'config.json', 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "openai.api_key = config['OPENAI_API_KEY']\n",
    "openai.api_base = config['OPENAI_API_BASE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5822a96",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e208e9e1c2a625f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def dataset_obtain(testfrac=0.2):\n",
    "    '''\n",
    "    获得 numpy 结构数据集\n",
    "    '''\n",
    "    datasets_path = {\n",
    "    'us_births': 'datasets/monash/us_births.pkl',  # daily\n",
    "    'saugeenday': 'datasets/monash/saugeenday.pkl'  # daily\n",
    "    }\n",
    "    datas = []\n",
    "    for name, data_path in datasets_path.items():\n",
    "        with open(data_path, 'rb') as file:\n",
    "            # 加载数据\n",
    "            data = pickle.load(file)\n",
    "        series = pd.Series(np.concatenate((data[0][0][0], data[0][0][1])))\n",
    "        splitpoint = int(len(series)*(1-testfrac))\n",
    "        train = series.iloc[:splitpoint]  # Only test the last couples of samples\n",
    "        test = series.iloc[splitpoint:]\n",
    "        datas.append((train,test))\n",
    "    return dict(zip(datasets_path.keys(),datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ad5fc45dd5d510",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the seasonal period for a given dataset.\n",
    "def period_get(name):\n",
    "    '''\n",
    "    Returns the known or manually estimated seasonal period for a specified dataset.\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the dataset.\n",
    "\n",
    "    Returns:\n",
    "        period (int): The seasonal period length. Default is 365 (e.g., for daily yearly data).\n",
    "    '''\n",
    "    period = 365  # Default period (e.g., daily data with yearly seasonality)\n",
    "    \n",
    "    if name == \"HeartRateDataset\":\n",
    "        period = 144\n",
    "    if name == \"GasRateCO2Dataset\":\n",
    "        period = 39\n",
    "    if name == \"AirPassengersDataset\":\n",
    "        period = 12\n",
    "    if name == \"AusBeerDataset\":\n",
    "        period = 4\n",
    "    if name == \"MonthlyMilkDataset\":\n",
    "        period = 12\n",
    "    if name == \"SunspotsDataset\":\n",
    "        period = 12\n",
    "    if name == \"WineDataset\":\n",
    "        period = 12\n",
    "    if name == \"WoolyDataset\":\n",
    "        period = 4\n",
    "    if name == \"IstanbulTraffic\":\n",
    "        period = 24\n",
    "    if name == \"TurkeyPower\":\n",
    "        period = 7    # Weekly cycle; manually estimated, not from official documentation\n",
    "    if name == \"us_birth\":\n",
    "        period = 7    # Weekly cycle; manually estimated, not from official documentation\n",
    "    if name == \"saugeenday\":\n",
    "        period = 7    # Weekly cycle; manually estimated, not from official documentation\n",
    "\n",
    "    return period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a86312e2f6a7729",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Univariate Timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b964063590477b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Data-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e792df90a937b0f2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing_data(train, test):\n",
    "    train_reshaped = train.values.reshape(-1, 1)\n",
    "    test_reshaped = test.values.reshape(-1, 1)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_reshaped)\n",
    "    standardized_train = scaler.transform(train_reshaped)\n",
    "    train = pd.Series(standardized_train.flatten(), index=train.index)\n",
    "    standardized_test = scaler.transform(test_reshaped)\n",
    "    test = pd.Series(standardized_test.flatten(), index=test.index)    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823206fd2fc89c12",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "datasets = get_datasets()  \n",
    "datasets_tmp = get_memorization_datasets()\n",
    "datasets.update(datasets_tmp)\n",
    "datasets_tmp = dataset_obtain()\n",
    "datasets.update(datasets_tmp)\n",
    "\n",
    "for name in datasets.keys():\n",
    "    train, test = datasets[name]\n",
    "    train, test = preprocessing_data(train, test)\n",
    "    dataset = (train, test)\n",
    "    datasets[name] = dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9166295",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbfb5620f79ad0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:20:08.615349200Z",
     "start_time": "2024-06-03T11:20:08.528749200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gpt4_hypers = dict(\n",
    "    alpha=0.3,\n",
    "    basic=True,\n",
    "    temp=1.0,\n",
    "    top_p=0.8,\n",
    "    settings=SerializerSettings(base=10, prec=3, signed=True, time_sep=', ', bit_sep='', minus_sign='-')\n",
    ")\n",
    "\n",
    "gpt3_hypers = dict(\n",
    "    temp=0.7,\n",
    "    alpha=0.95,\n",
    "    beta=0.3,\n",
    "    basic=False,\n",
    "    settings=SerializerSettings(base=10, prec=3, signed=True, half_bin_correction=True)\n",
    ")\n",
    "\n",
    "promptcast_hypers = dict(\n",
    "    temp=0.7,\n",
    "    settings=SerializerSettings(base=10, prec=0, signed=True,\n",
    "                                time_sep=', ',\n",
    "                                bit_sep='',\n",
    "                                plus_sign='',\n",
    "                                minus_sign='-',\n",
    "                                half_bin_correction=False,\n",
    "                                decimal_point='')\n",
    ")\n",
    "\n",
    "\n",
    "gemini_hypers = {\n",
    "    'temp': 0.2,  # recommended: [0.2, 0.4]\n",
    "    'alpha': 0.95,\n",
    "    'beta': 0.3,\n",
    "    'basic': [False],\n",
    "    'settings': [SerializerSettings(base=10, prec=3, signed=True,half_bin_correction=True)],  # recommended: prec=3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1588525fc95414e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:20:13.920248Z",
     "start_time": "2024-06-03T11:20:13.823125900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_hypers = {\n",
    "    'LLMTime GPT-3.5': {'model': 'gpt-3.5-turbo-instruct', **gpt3_hypers},\n",
    "    # 'LLMTime GPT-4': {'model': 'gpt-4', **gpt4_hypers},\n",
    "    # 'LLMTime GPT-3': {'model': 'text-davinci-003', **gpt3_hypers},\n",
    "    # 'PromptCast GPT-3': {'model': 'text-davinci-003', **promptcast_hypers},\n",
    "    # 'ARIMA': arima_hypers,\n",
    "    'gemini-1.0-pro': {'model': 'gemini-1.0-pro', **gemini_hypers},\n",
    "}\n",
    "\n",
    "model_predict_fns = {\n",
    "    'LLMTime GPT-3.5': get_llmtime_predictions_data,\n",
    "    # 'LLMTime GPT-4': get_llmtime_predictions_data,\n",
    "    # 'PromptCast GPT-3': get_promptcast_predictions_data,\n",
    "    # 'ARIMA': get_arima_predictions_data,\n",
    "    'gemini-1.0-pro': get_llmtime_predictions_data, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "880c8f2128b7ee5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:20:15.383599Z",
     "start_time": "2024-06-03T11:20:15.336604200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_names = list(model_predict_fns.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4667a85b81d3c3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Datasets(Darts and Monash_Not commonly used datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "859578a7ac92e806",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Selected datasets\n",
    "# name_list = ['GasRateCO2Dataset', 'WineDataset', 'SunspotsDataset', 'AusBeerDataset']\n",
    "\n",
    "# only for partial test \n",
    "name_list = ['AirPassengersDataset', 'AusBeerDataset', 'GasRateCO2Dataset', 'MonthlyMilkDataset', 'SunspotsDataset', 'WineDataset', 'WoolyDataset', 'HeartRateDataset', 'IstanbulTraffic', 'TSMCStock', 'TurkeyPower', 'us_births', 'saugeenday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcf00e0d625b15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:27:16.966599600Z",
     "start_time": "2024-06-03T11:27:16.891463400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def MA_process(name, train, test, test_length=96):\n",
    "    period = period_get(name)\n",
    "    data_tmp = pd.concat([train, test])\n",
    "    out = data_tmp.rolling(window=period).mean().dropna()\n",
    "    train_tmp = out[:-test_length]\n",
    "    test_tmp = out[-test_length:]\n",
    "    return train_tmp, test_tmp\n",
    "\n",
    "def metrics_computation(test, median_pred):\n",
    "    mse = mean_squared_error(test, median_pred)\n",
    "    mae = mean_absolute_error(test, median_pred)\n",
    "    mape = mean_absolute_percentage_error(test, median_pred) * 100\n",
    "    r2 = r2_score(test, median_pred)        \n",
    "    return mse, mae, mape, r2\n",
    "\n",
    "def MA_recover(data_pred, median_pred, record_tmp, record_list_tmp, period=8, whether_MA=False):\n",
    "    data_pred_tmp = copy.deepcopy(data_pred)\n",
    "    median_pred_tmp = copy.deepcopy(median_pred)\n",
    "    if whether_MA is True:\n",
    "        for index in range(data_pred.shape[1]):\n",
    "            if index >= period:\n",
    "                data_pred.iloc[:, index] = period * (data_pred_tmp.iloc[:, index]-data_pred_tmp.iloc[:, index-1])+data_pred.iloc[:, index-period]\n",
    "                median_pred.iloc[index] = period * (median_pred_tmp.iloc[index]-median_pred_tmp.iloc[index-1])+median_pred.iloc[index-period]\n",
    "            else:\n",
    "                if index == 0:\n",
    "                    data_pred.iloc[:, index] = period * (data_pred_tmp.iloc[:, index]-record_tmp)+record_list_tmp.iloc[index]\n",
    "                    median_pred.iloc[index] = period * (median_pred_tmp.iloc[index]-record_tmp)+record_list_tmp.iloc[index] \n",
    "                else:\n",
    "                    data_pred.iloc[:, index] = period * (data_pred_tmp.iloc[:, index]-data_pred_tmp.iloc[:, index-1])+record_list_tmp.iloc[index]\n",
    "                    median_pred.iloc[index] = period * (median_pred_tmp.iloc[index]-median_pred_tmp.iloc[index-1])+record_list_tmp.iloc[index]\n",
    "    return data_pred, median_pred\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f22989ad4672a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:27:18.177906900Z",
     "start_time": "2024-06-03T11:27:18.116814900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def forecasting_w_LLMs(datasets, name_list, model_names, whether_MA=False, pred_period=8, whether_multi=False):\n",
    "    \n",
    "    for name, dataset in datasets.items():\n",
    "        if name not in name_list:  \n",
    "            continue\n",
    "    \n",
    "        data = datasets[name]\n",
    "        train, test = data  \n",
    "\n",
    "        if name in ['us_births', 'saugeenday']:  \n",
    "            train = train.iloc[-3080:]  \n",
    "            test = test.iloc[:96]  \n",
    "        \n",
    "        test_original = copy.deepcopy(test)\n",
    "        record_list_tmp = train[-pred_period:]\n",
    "        \n",
    "        if whether_MA:\n",
    "            train, test = MA_process(name=name, train=train, test=test, test_length=len(test))\n",
    "        record_tmp = train.iloc[-1]\n",
    "    \n",
    "        for model in model_names: \n",
    "            print(model)\n",
    "            if model == 'gemini-1.0-pro':\n",
    "                whether_blank = False\n",
    "            else:\n",
    "                whether_blank = True\n",
    "            model_hypers[model].update({'dataset_name': name})  \n",
    "            hypers = list(grid_iter(model_hypers[model]))  \n",
    "            num_samples = 10  \n",
    "            \n",
    "            print(type(train))\n",
    "            pred_dict = get_autotuned_predictions_data(train, test, hypers, num_samples, model_predict_fns[model], verbose=False, parallel=False, whether_blanket=whether_blank, whether_multi=whether_multi) \n",
    "            data_pred = pred_dict['samples']  \n",
    "            median_pred = pred_dict['median'] \n",
    "            \n",
    "            data_pred, median_pred = MA_recover(data_pred=data_pred, median_pred=median_pred, record_tmp=record_tmp, record_list_tmp=record_list_tmp, period=pred_period, whether_MA=whether_MA)\n",
    "                            \n",
    "            pred_dict['samples'] = data_pred  \n",
    "            pred_dict['median'] = median_pred\n",
    "    \n",
    "            mse, mae, mape, r2 = metrics_computation(test_original, median_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b52040211eccdc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "whether_MA = False\n",
    "forecasting_w_LLMs(datasets, name_list, model_names, whether_MA=whether_MA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728e079d5dabcf7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### with MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066c52702ad1290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T19:21:28.503457900Z",
     "start_time": "2024-06-03T18:00:50.219233200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "whether_MA = True\n",
    "forecasting_w_LLMs(datasets, name_list, model_names, whether_MA=whether_MA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b60cfa840284c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Multi-variate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "23be34aa334a722e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_datasets_multi(n=-1, testfrac=0.2):\n",
    "    datasets = [\n",
    "        'electricity',\n",
    "        'ETTh1',  \n",
    "        'ETTh2',\n",
    "        'ETTm1',\n",
    "        'ETTm2', \n",
    "        'exchange_rate',\n",
    "        'national_illness',\n",
    "        'traffic',\n",
    "        'weather'\n",
    "    ]\n",
    "    datas = []\n",
    "    for i, dsname in enumerate(datasets):\n",
    "        path = f'datasets/multi_variate_datasets/{dsname}.csv'\n",
    "        series = pd.read_csv(path)\n",
    "        splitpoint = int(series.shape[0]*(1-testfrac))\n",
    "        train = series.iloc[:splitpoint]  # Only test the last couples of samples\n",
    "        test = series.iloc[splitpoint:]\n",
    "        datas.append((train,test))\n",
    "        if i+1==n:\n",
    "            break\n",
    "    return dict(zip(datasets,datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8e15c98dbe0e33a7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "datasets_tmp = get_datasets_multi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a82b1f3502b103",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Predict only 1 sequence each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e005725f26602a2f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'model': 'gpt-4', 'alpha': 0.3, 'basic': True, 'temp': 1.0, 'top_p': 0.8, 'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan'), 'dataset_name': 'electricity'}) \n",
      " with NLL inf\n",
      "warning: input_len 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943, 951, 970, 1018, 1075, 1171, 1250, 1226, 1231, 1307, 1274, 1313, 1410, 1450, 1501, 1421, 1306, 1284, 1204, 1151, 1121, 1086, 1063, 1037, 1016, 996, 1020, 961, 1030, 1123, 1186, 1198, 1320, 1337, 1376, 1384, 1369, 1408, 1459, 1385, 1334, 1301, 1141, 1167, 1109, 1025, 1049, 1009, 1007, 975, 1003, 936, 1046, 1158, 1180, 1237, 1266, 1307, 1305, 1361, 1457, 1528, 1488, 1324, 1259, 1261, 1181, 1154, 1136, 1101, 1048, 1055, 1023, 993, 970, 975, 1059, 1163, 1204, 1256, 1329, 1353, 1377, 1542, 1575, 1661, 1772, 1610, 1512, 1364, 1242, 1182, 1147, 1130, 1105, 1069, 1051, 1046, 1049, 1038, 1078, 1131, 1151, 1191, 1203, 1156, 1150, 1179, 1215, 1242, 1216, 1249, 1239, 1176, 1124, 1119, 1077, 1035, 1045, 1029, 1023, 1015, 982, 998, 936, 986, 964, 1031, 1034, 1010, 1024, 1068, 1036, 1080, 1050, 1021, 987, 999, 951, 973, 920, 937, 887, 923, 874, 915, 898, 913, 734, 1013, 952, 937, 992, 988, 944, 1005, 957, 990, 953, 950, 970, 945, 912, 950, 884, 909, 912, 899, 887, 890, 890, 972, 985, 1095, 1112, 1160, 1232, 1213, 1242, 1236, 1198, 1240, 1373, 1303, 1251, 1156, 1066, 1063, 1000, 972, 946, 951, 916, 912, 878, 929, 933, 1089, 1144, 1180, 1209, 1213, 1175, 1235, 1344, 1315, 1350, 1250, 1219, 1200, 1116, 1065, 1011, 996, 942, 953, 951, 930, 964, 963, 982, 1140, 1165, 1195, 1203, 1199, 1187, 1221, 1274, 1277, 1268, 1239, 1190, 1115, 1083, 1058, 971, 967, 924, 940, 933, 919, 915, 974, 982, 1141, 1189, 1219, 1266, 1275, 1209, 1192, 1258, 1252, 1342, 1333, 1280, 1169, 1116, 1109, 992, 968, 943, 959, 958, 946, 963, 955, 954, 1082, 1118, 1096, 1128, 1119, 1112, 1171, 1210, 1282, 1293, 1180, 1168, 1112, 1027, 1084, 1017, 1020, 964, 968, 957, 986, 1011, 977, 951, 1055, 1075, 1086, 1134, 1110, 1033, 1064, 1075, 1141, 1086, 1136, 1081, 1025, 972, 944, 913, 912, 863, 898, 828, 853, 848, 850, 796, 911, 893, 926, 974, 981, 961, 1017, 995, 1014, 990, 1001, 970, 946, 888, 933, 853, 865, 795, 834, 827, 822, 825, 890, 878, 1075, 1127, 1155, 1201, 1260, 1236, 1274, 1378, 1458, 1479, 1394, 1274, 1171, 1082, 1067, 948, 995, 935, 978, 942, 919, 901, 917, 981, 1138, 1184, 1228, 1292, 1310, 1297, 1353, 1421, 1452, 1688, 1527, 1450, 1232, 1184, 1134, 1078, 1057, 1038, 1030, 1003, 940, 975, 997, 995, 1119, 1224, 1304, 1356, 1394, 1381, 1300, 1357, 1453, 1637, 1345, 1283, 1189, 1134, 1097, 1013, 971, 939, 954, 938, 932, 936, 969, 989, 1100, 1136, 1154, 1215, 1273, 1244, 1290, 1343, 1380, 1428, 1380, 1296, 1167, 1095, 1088, 997, 998, 972, 993, 969, 954, 947, 964, 978, 1131, 1229, 1269, 1544, 1517, 1502, 1542, 1646, 1664, 1685, 1585, 1469, 1381, 1294, 1207, 1092, 1059, 1040, 1029, 1011, 1002, 984, 1004, 975, 1083, 1145, 1127, 1162, 1256, 1213, 1251, 1276, 1383, 1368, 1327, 1284, 1191, 1098, 1090, 1025, 1020, 952, 989, 915, 892, 899, 938, 888, 999, 997, 1047, 1067, 1109, 1130, 1171, 1175, 1189, 1174, 1155, 1106, 1074, 1021, 996, 962, 953, 919, 932, 895, 905, 881, 920, 935, 1089, 1198, 1228, 1289, 1353, 1361, 1475, 1611, 1650, 1626, 1547, 1425, 1257, 1150, 1122, 1011, 1004, 952, 967, 936, 915, 895, 920, 942, 1076, 1170, 1224, 1274, 1323, 1286, 1365, 1405, 1451, 1497, 1477, 1400, 1244, 1170, 1109, 1029, 1044, 984, 992, 959, 933, 931, 928, 928, 1055, 1149, 1214, 1265, 1326, 1323, 1394, 1517, 1525, 1546, 1507, 1415, 1242, 1109, 1104, 1014, 970, 960, 942, 907, 908, 885, 942, 982, 1130, 1230, 1265, 1315, 1466, 1413, 1428, 1480, 1485, 1442, 1443, 1420, 1271, 1190, 1157, 1081, 1008, 1030, 977, 978, 990, 951, 964, 996, 1124, 1192, 1286, 1370, 1467, 1471, 1475, 1584, 1690, 1646, 1546, 1479, 1319, 1258, 1256, 1171, 1172, 1142, 1111, 1061, 1025, 994, 979, 971, 1042, 1127, 1184, 1198, 1298, 1277, 1322, 1393, 1468, 1414, 1321, 1255, 1138, 1085, 1019, 1036, 1023, 984, 993, 914, 901, 903, 932, 897, 971, 981, 1016, 1050, 1094, 1082, 1113, 1123, 1120, 1062, 1058, 992, 998, 939, 951, 890, 891, 869, 884, 852, 860, 878, 940, 967, 1063, 1184, 1212, 1297, 1377, 1365, 1386, 1468, 1538, 1520, 1484, 1419, 1338, 1216, 1196, 1092, 1089, 1028, 1036, 1008, 987, 963, 985, 1016, 1151, 1287, 1340, 1412, 1454, 1454, 1482, 1617, 1716, 1749, 1700, 1584, 1443, 1319, 1278, 1183, 1181, 1116, 1099, 1069, 1039, 1029, 1044, 1084, 1232, 1343, 1372, 1472, 1551, 1555, 1632, 1659, 1693, 1767, 1738, 1670, 1587, 1380, 1294, 1221, 1205, 1192, 1184, 1130, 1094, 1098, 1086, 1166, 1294, 1427, 1486, 1623, 1684, 1678, 1827, 1849, 1890, 1846, 1708, 1688, 1488, 1404, 1338, 1221, 1211, 1136, 1166, 1110, 1078, 1132, 1069, 1088, 1223, 1268, 1292, 1408, 1415, 1423, 1500, 1640, 1748, 1866, 1743, 1585, 1402, 1323, 1292, 1202, 1182, 1126, 1124, 1116, 1031, 1002, 988, 1021, 1178, 1257, 1251, 1315, 1353, 1351, 1410, 1554, 1578, 1488, 1433, 1419, 1317, 1253, 1190, 1128, 1150, 1076, 1056, 969, 971, 933, 963, 911, 1041, 1112, 1046, 1088, 1151, 1160, 1205, 1221, 1238, 1242, 1225, 1154, 1112, 1030, 1030, 958, 981, 934, 959, 925, 944, 953, 945, 1016, 1130, 1294, 1330, 1352, 1332, 1274, 1293, 1358, 1367, 1408, 1357, 1262, 1149, 1070, 1071, 1001, 1012, 949, 950, 898, 909, 904, 919, 990, 1112, 1213, 1267, 1254, 1293, 1273, 1298, 1302, 1261, 1344, 1284, 1261, 1138, 1085, 1027, 956, 1028, 941, 973, 861, 896, 866, 867, 975, 1043, 1156, 1164, 1219, 1182, 1169, 1232, 1255, 1271, 1293, 1193, 1134, 1075, 1023, 1019, 944, 950, 927, 952, 866, 899, 900, 901, 989, 1074, 1176, 1211, 1288, 1279, 1247, 1237, 1288, 1331, 1342, 1317, 1269, 1170, 1125, 1079, 1033, 1023, 987, 981, 944, 935, 937, 931, 985, 1092, 1196, 1192, 1239, 1291, 1273, 1273, 1297, 1352, 1396, 1294, 1240, 1153, 1081, 1057, 989, 1000, 990, 992, 955, 942, 915, 929, 927, 1005, 1090, 1157, 1124, 1219, 1134, 1191, 1197, 1225, 1164, 1123, 1074, 1038, 988, 1015, 956, 977, 933, 956, 897, 917, 905, 904, 881, 975, 987, 1011, 1008, 1027, 1001, 1037, 1001, 1035, 1017, 1013, 992, 967, 939, 964, 886, 935, 883, 912, 881, 903, 894, 897, 940, 1070, 1148, 1164, 1178, 1190, 1179, 1139, 1238, 1260, 1341, 1253, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:17<00:00, 17.81s/it]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prediction too short 25 < 96, padded with last value\n",
      "Warning: Prediction too short 8 < 96, padded with last value\n",
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'model': 'gpt-4', 'alpha': 0.3, 'basic': True, 'temp': 1.0, 'top_p': 0.8, 'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan'), 'dataset_name': 'ETTh1'}) \n",
      " with NLL inf\n",
      "warning: input_len 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2096, 2257, 2257, 2290, 2128, 2225, 1838, 2032, 2000, 2160, 2451, 2709, 2354, 3612, 3902, 3451, 3612, 3160, 2935, 2451, 2419, 2225, 2193, 2193, 2225, 2290, 2386, 2290, 2257, 2160, 2225, 2354, 2451, 2419, 2806, 3580, 3419, 4257, 4451, 3612, 3580, 3386, 3032, 2870, 2870, 2741, 2354, 2515, 2483, 2322, 2741, 2290, 2386, 2612, 2483, 2290, 2322, 2935, 2999, 3419, 3483, 3612, 3773, 2967, 2838, 3032, 2612, 2709, 2612, 2128, 1677, 1677, 1645, 1677, 2000, 1838, 1902, 1354, 1419, 1193, 1419, 1096, 1354, 2064, 1322, 1773, 1935, 1612, 1677, 2128, 2290, 2128, 2290, 2193, 2128, 1935, 2064, 1773, 2096, 2419, 2451, 2290, 2257, 2193, 2451, 2225, 2386, 2709, 2515, 3225, 3419, 2870, 2741, 2773, 2386, 2160, 2096, 2225, 2193, 2032, 1967, 2290, 2225, 1967, 1870, 1967, 1773, 1902, 2032, 2160, 1870, 2225, 2451, 2483, 2515, 2515, 2515, 2709, 2644, 2612, 2354, 1967, 1806, 1709, 1515, 1483, 1354, 1193, 1193, 1000, 870, 1064, 1000, 1000, 1096, 1128, 1290, 1419, 1290, 1322, 1386, 1580, 1515, 1515, 1709, 1870, 1741, 1870, 1902, 1967, 2000, 2128, 2193, 2386, 2354, 2451, 2064, 2354, 2096, 2290, 2225, 2483, 2354, 2773, 2967, 2870, 2547, 2451, 2612, 2677, 2870, 2838, 2999, 3032, 2999, 2999, 3064, 3225, 3160, 3128, 3515, 3257, 3677, 3677, 2999, 3096, 3257, 3289, 3322, 3612, 2999, 3032, 3193, 2902, 2677, 3322, 3257, 3419, 3096, 2322, 2096, 1483, 1548, 1838, 2000, 1483, 1515, 1838, 1225, 1160, 1709, 1225, 1515, 1806, 2160, 1902, 1935, 1967, 1967, 2032, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 1935, 2386, 2064, 2290, 1967, 1902, 1838, 1838, 1645, 1483, 1580, 1548, 2032, 1773, 1935, 2257, 1806, 1902, 1806, 1709, 1580, 1483, 1419, 1322, 1322, 1322, 1612, 1741, 1773, 1773, 1773, 2128, 2225, 2160, 2225, 2322, 2612, 2741, 2515, 2709, 3160, 2838, 3032, 2322, 2032, 1902, 1773, 2000, 1612, 1580, 1225, 838, 1000, 322, 838, 1000, 870, 386, 0, 741, 0, 0, -290, 0, -580, -548, -870, -935, -967, -1032, -1032, -1064, -1096, -935, -1225, -1258, -1160, -1225, -1128, -1193, -1128, -1064, -1032, -1032, -1000, -903, -967, -935, -935, -967, -967, -1160, -1000, -967, -709, -645, -483, 0, 0, 0, 0, 0, 0, 0, 0, 0, 290, 451, 354, 741, 1000, 1645, 1322, 1193, 1354, 1354, 1548, 1580, 1225, 1322, 1225, 1258, 1225, 1064, 1290, 806, 967, 354, 451, 419, 225, 548, 806, 516, 613, 580, 548, 580, -225, -386, 0, 0, 0, 0, 386, 516, 645, 838, 1096, 1160, 1483, 1645, 0, 386, 290, 0, 0, 0, 0, 0, 0, 354, 0, 0, 677, 354, 258, -290, 0, 0, 290, 451, 741, 419, 290, 290, 0, 838, 290, 290, 741, 483, 290, 386, 0, 0, 0, 0, -354, -386, 0, 0, -225, 0, 451, 1064, 1160, 1225, 1225, 1322, 1386, 1645, 1258, 1193, 1258, 1000, 1451, 1709, 1483, 1645, 1935, 1935, 1709, 2160, 1741, 2032, 1451, 1000, 935, 935, 967, 967, 1193, 1160, 1160, 806, 741, 1322, 1773, 1322, 1193, 1128, 1322, 1258, 1032, 1419, 1258, 1548, 1386, 1483, 1645, 1451, 1451, 1225, 1677, 1483, 1548, 1612, 1193, 1773, 1838, 2064, 2386, 1870, 1870, 2064, 1322, 1902, 1548, 1548, 1290, 1290, 1160, 838, 1000, 1225, 1225, 1193, 1419, 1160, 1160, 1160, 1096, 1225, 1032, 1160, 2160, 1902, 1741, 2225, 1741, 2225, 1838, 1677, 1580, 1419, 1000, 1000, 1258, 1096, 773, 935, 1032, 773, 1032, 1000, 709, 741, 903, 806, 935, 967, 935, 1160, 1160, 1064, 1160, 1064, 1000, 1193, 1032, 1160, 1160, 935, 1354, 1193, 1451, 1419, 1322, 1451, 1290, 1515, 1322, 2064, 2483, 2547, 2644, 3064, 3096, 3257, 3741, 2967, 3032, 2612, 2644, 2741, 2644, 2709, 2773, 2741, 2709, 2677, 2644, 2128, 1838, 2000, 1773, 2225, 2806, 2580, 2838, 3257, 2741, 2741, 2902, 2870, 3032, 2773, 2483, 2870, 2580, 2838, 3128, 3257, 3419, 3354, 3483, 2612, 2547, 2322, 2257, 1709, 2515, 2128, 1290, 1096, 1580, 1870, 1645, 1645, 2064, 2160, 2193, 2483, 1612, 1322, 1580, 1677, 2257, 2612, 2773, 3032, 2741, 2515, 2935, 3193, 3257, 2838, 2419, 2257, 2644, 2967, 2677, 2322, 2225, 2386, 2580, 2322, 2290, 2096, 2160, 2096, 2000, 1870, 1967, 1773, 1967, 1967, 1967, 1902, 1967, 1741, 1967, 2064, 1935, 2064, 2096, 2160, 1741, 1709, 1773, 2032, 2128, 2290, 2096, 2290, 2257, 2354, 2451, 2451, 2709, 2741, 2193, 2386, 2483, 2870, 3032, 2741, 2870, 2999, 3193, 2773, 2773, 2806, 2741, 2709, 2870, 2612, 2935, 2806, 2709, 2515, 2806, 2709, 2483, 2386, 2354, 2160, 2064, 2257, 2257, 2290, 2160, 2290, 2225, 2386, 2451, 2612, 2644, 2741, 2580, 2483, 2644, 2612, 2451, 2257, 2193, 2096, 1902, 2064, 2225, 2064, 2096, 1967, 2322, 1773, 1902, 1677, 1000, 1193, 1160, 1483, 2160, 2193, 2419, 2677, 2644, 2547, 2064, 2160, 2290, 1612, 1677, 1645, 2290, 2515, 2644, 2806, 2322, 2322, 2515, 2451, 2612, 2515, 2419, 2451, 2257, 2160, 2290, 2322, 2193, 2032, 1483, 2032, 1064, 773, 935, 1709, 1193, 1225, 1160, 1225, 1386, 1451, 1096, 1322, 1096, 935, 935, 935, 838, 903, 935, 741, 677, 580, 419, 419, 516, 354, 193, 0, 0, 0, 0, 0, 0, 0, -451, -613, -516, -386, 0, -386, -741, -967, -741, -580, -870, -935, -1064, -838, -741, -1128, -1128, -1000, -1064, -1096, -1290, -1258, -1386, -1128, -1419, -1322, -1096, -1419, -1386, -1354, -773, -741, -613, -741, -709, -870, -870, -870, -741, -386, -580, -516, -483, 0, -613, -258, 0, 0, 0, 0, 0, 0, 225, 386, 0, 0, 0, 0, 0, 0, -290, -290, -322, -580, -935, -1128, -1709, -1548, -1483, -1515, -1419, -1225, -903, -967, -548, -516, 0, 0, 0, 0, 0, 0, -354, -354, -419, -386, -613, -419, -419, -548, -613, -677, -419, -548, 0, -451, -451, 0, 290, 483, 322, 0, 0, 0, 0, 0, 258, 258, 516, 419, 483, 677, 354, 354, 613, 322, 354, 225, 516, 677, 773, 741, 903, 806, 677, 709, 741, 773, 870, 838, 613, 741, 483, 580, 451, 483, 451, 419, 773, 967, 1096, 1386, 1419, 1902, 1548, 1580, 1258, 1096, 1000, 1258, 1160, 1258, 1386, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 806, 1258, 1386, 1386, 1483, 1322, 1258, 1128, 935, 1096, 1451, 1741, 2160, 1967, 1967, 2870, 1806, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:19<00:00, 19.64s/it]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prediction too short 94 < 96, padded with last value\n",
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'model': 'gpt-4', 'alpha': 0.3, 'basic': True, 'temp': 1.0, 'top_p': 0.8, 'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan'), 'dataset_name': 'ETTh2'}) \n",
      " with NLL inf\n",
      "warning: input_len 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1368, 1246, 1124, 1003, 911, 820, 759, 698, 668, 1094, 1581, 2098, 2494, 2737, 3072, 3072, 2951, 2707, 2464, 2220, 1977, 1855, 1824, 1824, 1824, 1763, 1611, 1490, 1368, 1307, 1307, 1246, 1185, 1581, 2007, 2494, 2981, 3316, 3681, 3681, 3651, 3377, 3011, 2707, 2494, 2281, 2159, 2098, 2098, 2098, 2098, 2037, 2007, 1977, 1916, 1885, 1855, 1916, 2220, 2555, 2798, 3072, 3285, 3346, 3255, 3103, 2981, 2859, 2798, 2738, 2677, 2646, 2555, 2494, 2433, 2342, 2220, 2159, 2037, 1977, 1916, 1977, 2129, 2342, 2585, 2707, 2737, 2737, 2677, 2494, 2311, 2129, 1946, 1794, 1672, 1611, 1490, 1368, 1216, 1094, 1003, 911, 820, 759, 729, 1033, 1611, 2129, 2524, 2768, 3042, 2951, 2677, 2433, 2159, 1916, 1733, 1611, 1490, 1368, 1276, 1185, 1185, 1185, 1094, 1033, 972, 911, 850, 1094, 1550, 2159, 2677, 3011, 3255, 3255, 3164, 2920, 2646, 2342, 2190, 2068, 1977, 1916, 1855, 1703, 1581, 1459, 1429, 1307, 1216, 1185, 1216, 1398, 1703, 2098, 2433, 2555, 2585, 2585, 2524, 2403, 2342, 2311, 2281, 2281, 2281, 2281, 2250, 2190, 2190, 2190, 2159, 2159, 2159, 2098, 2098, 2037, 1977, 1946, 1916, 2007, 2037, 2068, 2098, 2159, 2190, 2220, 2250, 2250, 2250, 2220, 2220, 2159, 2098, 2098, 2068, 2068, 2068, 2068, 2098, 2098, 2220, 2342, 2494, 2555, 2585, 2646, 2646, 2646, 2646, 2585, 2555, 2555, 2524, 2524, 2524, 2524, 2494, 2464, 2372, 2220, 2220, 2220, 2220, 2250, 2281, 2281, 2220, 2250, 2250, 2159, 2098, 2037, 1977, 1946, 1916, 1824, 1733, 1672, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1611, 1368, 1368, 1307, 1307, 1246, 1246, 1216, 1155, 1155, 1368, 1703, 2129, 2494, 2677, 2951, 2981, 2859, 2616, 2433, 2220, 2159, 2129, 2129, 2159, 2159, 2159, 2129, 2098, 2068, 2068, 2007, 2007, 2037, 2098, 2250, 2372, 2464, 2585, 2737, 2737, 2707, 2646, 2585, 2524, 2464, 2372, 2342, 2281, 2250, 2098, 2007, 1855, 1733, 1611, 1550, 1490, 1459, 1429, 1550, 1550, 1550, 1429, 1337, 1246, 1185, 1124, 1063, 1003, 1003, 942, 942, 881, 790, 759, 698, 576, 546, 516, 516, 516, 546, 516, 576, 668, 759, 820, 911, 881, 881, 881, 881, 850, 820, 850, 881, 881, 850, 820, 820, 820, 820, 820, 850, 789, 759, 759, 850, 972, 1033, 1155, 1337, 1398, 1429, 1429, 1398, 1368, 1276, 1216, 1124, 1094, 1094, 1094, 1063, 1003, 911, 790, 729, 729, 790, 850, 1003, 1398, 1672, 1581, 1490, 1429, 1368, 1276, 1216, 1185, 1155, 1124, 1124, 1124, 1124, 1185, 1216, 1216, 1216, 1216, 1216, 1246, 1216, 1216, 1185, 1216, 1337, 1337, 1276, 1337, 1337, 1337, 1276, 1246, 1246, 1216, 1216, 1155, 1155, 1094, 1063, 972, 911, 850, 820, 820, 790, 820, 1003, 1246, 1368, 1429, 1672, 1703, 1581, 1337, 1094, 972, 942, 942, 942, 942, 972, 972, 972, 881, 789, 698, 637, 576, 576, 911, 1337, 1703, 2068, 2159, 2372, 2311, 2220, 1977, 1764, 1642, 1550, 1520, 1459, 1429, 1398, 1337, 1307, 1246, 1155, 1063, 1003, 942, 881, 1033, 1368, 1794, 2220, 2281, 2494, 2342, 2159, 1824, 1611, 1429, 1337, 1246, 1155, 1003, 911, 820, 698, 576, 485, 394, 333, 303, 303, 668, 1155, 1672, 2098, 2250, 2524, 2372, 2220, 1916, 1672, 1520, 1368, 1246, 1155, 1033, 911, 790, 637, 485, 363, 272, 181, 120, 89, 455, 881, 1337, 1824, 1976, 2311, 2281, 2159, 1885, 1520, 1276, 1155, 1003, 911, 850, 729, 607, 485, 363, 303, 242, 181, 120, 59, 455, 759, 1155, 1307, 1490, 1672, 1733, 1642, 1611, 1550, 1459, 1368, 1337, 1277, 1307, 1307, 1368, 1368, 1368, 1337, 1246, 1216, 1185, 1185, 1277, 1459, 1642, 1885, 2159, 2342, 2555, 2768, 2737, 2494, 2220, 1977, 1794, 1672, 1550, 1490, 1368, 1246, 1124, 1033, 911, 850, 790, 759, 1094, 1733, 2464, 3103, 3346, 3711, 3772, 3772, 3498, 3225, 2951, 2829, 2738, 2707, 2677, 2677, 2616, 2616, 2555, 2494, 2403, 2342, 2281, 2250, 2159, 2250, 2342, 2433, 2464, 2311, 2129, 2037, 1977, 1946, 1916, 1885, 1916, 1946, 1977, 1977, 1977, 1946, 1885, 1824, 1763, 1733, 1733, 1733, 1763, 1946, 2311, 2555, 2677, 2798, 2768, 2677, 2555, 2342, 2159, 1977, 1855, 1733, 1672, 1550, 1490, 1429, 1368, 1307, 1276, 1246, 1246, 1307, 1520, 1794, 1916, 2037, 2159, 2311, 2372, 2342, 2281, 2220, 2220, 2220, 2220, 2220, 2190, 2190, 2159, 2129, 2098, 2037, 1977, 1824, 1733, 1672, 1672, 1672, 1733, 1824, 1916, 1946, 2007, 2037, 2068, 2068, 2068, 2068, 2037, 2037, 1977, 1977, 1916, 1916, 1794, 1733, 1672, 1672, 1611, 1611, 1672, 1794, 2007, 2129, 2190, 2281, 2311, 2342, 2342, 2342, 2281, 2250, 2220, 2190, 2129, 2129, 2037, 1977, 1916, 1855, 1855, 1855, 1855, 1855, 1916, 2007, 2129, 2220, 2250, 2129, 2007, 1885, 1794, 1733, 1672, 1611, 1611, 1611, 1581, 1611, 1611, 1581, 1490, 1337, 1246, 1246, 1216, 1216, 1337, 1703, 1977, 2098, 2098, 2129, 2281, 2342, 2311, 2098, 1855, 1672, 1550, 1490, 1490, 1520, 1550, 1550, 1550, 1550, 1520, 1490, 1459, 1398, 1337, 1337, 1337, 1429, 1490, 1520, 1490, 1429, 1368, 1276, 1246, 1246, 1185, 1185, 1155, 1094, 1033, 1033, 972, 972, 911, 850, 790, 759, 729, 759, 820, 820, 850, 911, 942, 881, 820, 790, 790, 729, 668, 698, 668, 637, 546, 455, 394, 333, 303, 303, 303, 211, 211, 211, 242, 242, 242, 242, 242, 303, 303, 303, 303, 303, 363, 363, 424, 394, 333, 333, 303, 303, 303, 303, 303, 363, 455, 546, 607, 668, 698, 850, 972, 1003, 911, 820, 790, 759, 729, 698, 668, 607, 607, 546, 546, 485, 485, 455, 272, 211, 89, -31, 59, 120, 242, 303, 394, 455, 455, 546, 546, 546, 546, 546, 607, 607, 576, 516, 485, 485, 455, 455, 455, 424, 394, 394, 455, 485, 516, 546, 607, 668, 729, 729, 729, 698, 668, 607, 576, 576, 546, 546, 516, 455, 394, 363, 333, 303, 363, 546, 698, 850, 1003, 1155, 1246, 1216, 1063, 911, 729, 576, 424, 303, 242, 120, 59, -1, -31, -123, -184, -305, -366, -366, -244, 150, 759, 1337, 1672, 1885, 1672, 1459, 1155, 972, 820, 698, 607, 546, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 424, 455, 363, 242, 181, 59, -1, -62, -123, -123, 150, 698, 1368, 1916, 2159, 2190, 2098, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:21<00:00, 21.63s/it]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prediction too short 75 < 96, padded with last value\n",
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'model': 'gpt-4', 'alpha': 0.3, 'basic': True, 'temp': 1.0, 'top_p': 0.8, 'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan'), 'dataset_name': 'ETTm1'}) \n",
      " with NLL inf\n",
      "warning: input_len 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5185, 4998, 4873, 4998, 5122, 5060, 5060, 5060, 4935, 4685, 4685, 4248, 3998, 3810, 4248, 3936, 4185, 4373, 4436, 4436, 4436, 4373, 3748, 3061, 3123, 3748, 3623, 3186, 3248, 3810, 3936, 4248, 3186, 3623, 4123, 4061, 4436, 4436, 4436, 4498, 4873, 5122, 5498, 5247, 5122, 5309, 5622, 5560, 5435, 4685, 4436, 4248, 4498, 4623, 4248, 4498, 4498, 4436, 4310, 4623, 4873, 4747, 5060, 4873, 4747, 4747, 4810, 4998, 5060, 5247, 5435, 4747, 4873, 4685, 4810, 4685, 4685, 4623, 4810, 4747, 4747, 4747, 4623, 4623, 4373, 4498, 4373, 4436, 4185, 4248, 4185, 4436, 4436, 4623, 4436, 4623, 4498, 3623, 4373, 4373, 4248, 3998, 3810, 4123, 3936, 3998, 3685, 3248, 2873, 2936, 3310, 3936, 3936, 2748, 2436, 2248, 2061, 1999, 1999, 1624, 1499, 1374, 1374, 1436, 1811, 2936, 3061, 3373, 3310, 3873, 2936, 2248, 2311, 2373, 2436, 2248, 2373, 2561, 2436, 2311, 2248, 1936, 2186, 2311, 2373, 2624, 2499, 2624, 2686, 2999, 2561, 2436, 2811, 2624, 2686, 2624, 2124, 2499, 2624, 2811, 2561, 2624, 2561, 2311, 2124, 1936, 2061, 2061, 1811, 1873, 1749, 1936, 1811, 1873, 1936, 1936, 1811, 1749, 1811, 1624, 1624, 1811, 1749, 1811, 1749, 1873, 1811, 1686, 1811, 1873, 1936, 1811, 1436, 1374, 1562, 1436, 1311, 1311, 1187, 1187, 1124, 1249, 1249, 1187, 812, 624, 812, 687, 812, 687, 749, 936, 1000, 1124, 687, 436, 687, 562, 0, 374, 374, 500, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -562, -749, -436, -874, -562, -1000, -1311, -1187, -1562, -1562, -1187, -1000, -1062, -1062, -874, -749, -500, -436, -436, 0, -436, -500, -500, -749, -874, -1249, -1249, -1436, -1562, -1686, -1562, -1873, -1686, -1686, -1499, -1436, -1249, -1249, -1000, -1124, -1499, -1562, -1624, -1686, -1999, -1811, -1811, -1811, -1811, -1873, -2124, -2061, -1999, -1999, -1749, -1624, -1686, -1562, -1499, -1436, -1499, -1749, -1999, -2186, -2186, -1999, -2124, -2186, -2499, -2436, -2311, -1936, -1811, -1499, -1999, -2061, -2124, -2186, -2373, -2124, -1999, -1873, -2311, -2499, -2499, -2436, -2186, -2436, -2624, -2748, -2499, -2686, -2499, -2499, -2311, -2186, -2373, -2311, -2561, -2748, -2248, -2624, -2811, -2561, -2499, -2186, -2186, -2124, -2186, -2436, -2624, -2748, -3061, -2686, -2686, -2686, -2686, -2748, -2436, -2624, -2499, -1811, -1187, -1499, -1562, -1436, -1562, -1436, -1187, -1374, -1124, -1187, -1000, -1249, -1374, -1436, -1499, -1499, -1624, -1374, -1686, -1562, -1562, -1686, -1749, -1562, -1499, -1686, -1624, -1686, -1686, -1686, -1749, -1624, -1499, -1436, -1311, -1311, -1249, -749, -874, -936, -812, -1124, -1124, -1124, -1124, -1000, -1124, -1187, -1187, -936, -1124, -936, -624, 0, -749, -1249, -1562, -1187, -1311, -1124, -1062, -500, -500, 0, -562, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 500, 0, 0, 436, 0, 0, 0, 749, 624, 500, 436, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -562, -812, 0, -687, -562, -687, -624, -812, -624, -500, -687, -812, -1124, -1187, -1374, -1686, -1811, -2186, -1999, -2061, -2186, -2936, -2936, -3186, -3310, -2748, -3186, -2999, -2999, -2748, -2811, -2936, -2873, -2936, -2936, -3061, -2936, -3186, -3186, -2999, -2748, -2624, -2311, -2373, -2373, -1999, -1749, -1749, -1749, -1999, -1686, -1811, -1873, -1624, -1436, -1374, -1062, -1311, -1187, -1000, -1000, -936, -874, -436, 0, 0, 0, 0, 0, 0, 0, 0, 0, -500, -562, -562, 0, 0, 0, 0, 0, 0, 0, 0, 0, -500, -687, -687, -687, -624, -874, -874, -687, -1000, -812, -624, -812, -936, -874, -1000, -749, -812, -1187, -1374, -1187, -812, -687, -812, -812, -874, -874, -1000, -812, -687, -1000, -874, -1062, -1187, -1499, -1187, -1187, -1311, -1436, -1374, -1311, -1124, -436, -562, -812, -1374, -1436, -1374, -1062, -1499, -1499, -562, 0, 0, -436, -936, -874, -936, -1124, -874, -874, -500, -500, 0, 0, 0, 0, 436, 562, 0, 874, 1000, 936, 1311, 1000, 1062, 624, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 874, 0, 0, 500, 374, 0, 0, 500, 749, 687, 1000, 1000, 936, 812, 749, 812, 812, 687, 874, 936, 1000, 1187, 1311, 1311, 687, 562, 812, 687, 562, 0, 562, 687, 562, 1062, 1124, 1187, 812, 812, 749, 624, 436, 687, 562, 687, 0, 0, 0, 436, 0, 374, 1062, 1000, 749, 874, 1249, 1311, 1000, 1436, 1562, 1499, 1436, 1311, 1436, 1436, 1062, 1686, 1811, 1749, 1999, 2124, 1749, 1562, 1436, 1311, 1374, 1311, 1499, 1499, 1624, 1374, 1686, 1499, 1499, 1436, 1374, 1436, 1311, 1499, 1311, 1436, 1374, 1686, 1499, 1499, 1311, 1624, 1249, 1187, 1374, 1187, 1249, 1436, 1311, 1436, 1499, 1249, 1000, 936, 1187, 1124, 1124, 1124, 1311, 1187, 936, 874, 874, 874, 936, 936, 1249, 1124, 749, 874, 687, 687, 749, 812, 936, 1249, 874, 1499, 1749, 1749, 1749, 1873, 1999, 2186, 2061, 2124, 2499, 2624, 2499, 2686, 2248, 2561, 2561, 2748, 3373, 3186, 3248, 3685, 3685, 3623, 3436, 2999, 3061, 2999, 3061, 3061, 2999, 2811, 2873, 2436, 2499, 1999, 2311, 2124, 2186, 1999, 2124, 1936, 2186, 2124, 2311, 2436, 2436, 2373, 2436, 2248, 2186, 2248, 2436, 2436, 2248, 2748, 2373, 2686, 2873, 1873, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 1562, 2436, 2686, 2748, 2748, 2686, 2561, 2561, 2936, 2686, 2873, 3061, 2936, 2873, 2811, 2748, 2436, 2561, 2311, 2248, 2436, 2436, 2311, 2436, 2124, 2186, 2311, 2124, 1873, 1811, 1686, 1999, 1999, 2124, 2311, 2373, 2811, 2811, 2748, 2624, 3186, 3373, 3623, 3685, 4061, 4185, 3998, 3498, 3810, 3810, 3998, 3748, 3936, 3810, 3873, 4373, 5185, 5560, 4873, 4623, 4310, 3498, 3561, 3685, 3310, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:19<00:00, 19.11s/it]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'model': 'gpt-4', 'alpha': 0.3, 'basic': True, 'temp': 1.0, 'top_p': 0.8, 'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan'), 'dataset_name': 'ETTm2'}) \n",
      " with NLL inf\n",
      "warning: input_len 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3794, 3794, 3794, 3794, 3794, 3794, 3794, 3722, 3722, 3722, 3651, 3579, 3507, 3292, 3292, 3149, 3149, 3149, 3006, 3006, 2934, 3006, 3006, 2934, 2934, 2934, 2862, 2862, 2862, 2862, 2862, 2862, 2862, 2862, 2934, 3006, 3149, 3364, 3507, 3794, 4009, 4295, 4511, 4654, 4654, 4797, 4797, 4797, 4940, 4940, 4940, 4940, 4940, 4940, 4869, 4869, 5012, 5084, 5156, 5299, 5370, 5442, 5514, 5514, 5514, 5514, 5514, 5514, 5442, 5370, 5227, 5084, 4940, 4797, 4654, 4511, 4367, 4367, 4224, 4081, 3937, 3937, 3794, 3794, 3651, 3651, 3507, 3507, 3507, 3507, 3507, 3507, 3507, 3507, 3579, 3579, 3579, 3579, 3651, 3651, 3651, 3651, 3651, 3651, 3651, 3651, 3651, 3651, 3651, 3651, 3651, 3651, 3651, 3651, 3651, 3579, 3579, 3579, 3579, 3507, 3507, 3507, 3507, 3507, 3436, 3436, 3293, 3293, 3293, 3149, 3149, 3149, 3149, 3149, 3149, 3149, 3149, 3149, 3149, 3149, 3149, 3221, 3221, 3364, 3364, 3507, 3507, 3507, 3507, 3507, 3579, 3579, 3579, 3579, 3579, 3507, 3507, 3507, 3436, 3364, 3364, 3364, 3221, 3221, 3221, 3149, 3077, 3077, 3006, 3006, 2934, 2934, 2934, 2934, 2934, 2934, 2934, 2863, 2863, 2791, 2791, 2791, 2791, 2791, 2791, 2791, 2719, 2719, 2719, 2719, 2647, 2647, 2576, 2576, 2576, 2432, 2432, 2432, 2432, 2432, 2432, 2432, 2432, 2432, 2289, 2289, 2289, 2289, 2289, 2289, 2289, 2289, 2146, 2146, 2146, 2003, 2003, 2003, 2003, 1931, 1859, 1859, 1859, 1788, 1788, 1716, 1716, 1716, 1716, 1716, 1716, 1716, 1788, 1788, 1788, 1859, 1931, 1931, 1931, 1931, 1931, 1931, 1931, 1931, 2003, 2074, 2074, 2146, 2146, 2218, 2218, 2218, 2218, 2218, 2146, 2074, 2074, 2003, 2003, 1931, 1931, 1931, 1931, 1931, 1859, 1859, 1859, 1859, 1859, 1859, 1788, 1716, 1716, 1716, 1644, 1573, 1573, 1573, 1644, 1644, 1644, 1644, 1644, 1573, 1573, 1573, 1573, 1501, 1501, 1501, 1429, 1286, 1286, 1286, 1143, 1143, 1071, 1071, 1000, 928, 928, 856, 856, 856, 784, 784, 784, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 570, 570, 570, 498, 498, 498, 498, 498, 426, 498, 498, 498, 570, 570, 570, 570, 570, 570, 570, 570, 570, 570, 570, 570, 570, 570, 570, 570, 570, 570, 570, 570, 570, 641, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 785, 856, 856, 856, 856, 856, 856, 928, 928, 1000, 1000, 1000, 1000, 928, 928, 928, 856, 785, 785, 785, 785, 785, 785, 785, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 856, 856, 856, 999, 1071, 1143, 1214, 1214, 1286, 1286, 1358, 1358, 1429, 1501, 1501, 1501, 1573, 1573, 1573, 1573, 1644, 1716, 1859, 1931, 2003, 2074, 2218, 2289, 2289, 2361, 2361, 2361, 2361, 2289, 2289, 2146, 2146, 2074, 2003, 2003, 1931, 1859, 1859, 1859, 1859, 1859, 1788, 1788, 1788, 1788, 1716, 1716, 1716, 1716, 1716, 1644, 1644, 1573, 1573, 1573, 1573, 1501, 1501, 1429, 1429, 1429, 1429, 1429, 1429, 1429, 1429, 1286, 1286, 1286, 1286, 1286, 1286, 1286, 1143, 1143, 1143, 1143, 1143, 1143, 1143, 1143, 1143, 1071, 1071, 1000, 856, 784, 641, 641, 570, 498, 498, 355, 355, 283, 211, 211, 68, -74, -74, -74, -74, -3, 140, 140, 211, 283, 283, 426, 426, 570, 570, 570, 641, 713, 713, 784, 784, 856, 928, 928, 1071, 1071, 1071, 1071, 1071, 1071, 1071, 1214, 1214, 1214, 1286, 1286, 1286, 1286, 1286, 1286, 1286, 1286, 1286, 1286, 1286, 1286, 1286, 1286, 1286, 1286, 1286, 1286, 1429, 1429, 1429, 1429, 1429, 1429, 1429, 1429, 1429, 1358, 1358, 1286, 1286, 1214, 1214, 1214, 1214, 1143, 1143, 1143, 1143, 1143, 1143, 1143, 1143, 1071, 1071, 1071, 1071, 1071, 1071, 1071, 1071, 1071, 1071, 1071, 1071, 1000, 1000, 928, 928, 928, 928, 928, 928, 928, 928, 1000, 1000, 1000, 1071, 1071, 1071, 1071, 1143, 1214, 1214, 1214, 1214, 1214, 1214, 1214, 1286, 1286, 1358, 1358, 1429, 1429, 1429, 1573, 1573, 1573, 1573, 1644, 1716, 1716, 1716, 1716, 1716, 1716, 1716, 1716, 1716, 1716, 1716, 1716, 1644, 1573, 1573, 1573, 1573, 1429, 1429, 1429, 1429, 1429, 1429, 1429, 1358, 1358, 1358, 1358, 1358, 1358, 1358, 1286, 1286, 1286, 1286, 1286, 1286, 1286, 1214, 1214, 1214, 1214, 1143, 1143, 1071, 1000, 1000, 928, 928, 928, 856, 856, 856, 856, 784, 784, 784, 713, 713, 713, 713, 713, 713, 785, 856, 1000, 1071, 1143, 1286, 1429, 1501, 1644, 1644, 1716, 1788, 1859, 2003, 2074, 2146, 2289, 2361, 2361, 2504, 2576, 2719, 2791, 2863, 2934, 2934, 2934, 2934, 2863, 2863, 2719, 2719, 2647, 2504, 2433, 2289, 2146, 2146, 2003, 1859, 1859, 1716, 1573, 1501, 1358, 1358, 1214, 1214, 1071, 1000, 928, 856, 785, 713, 713, 570, 570, 570, 426, 426, 426, 283, 283, 211, 140, 140, 140, 68, -3, -3, -3, -3, -74, -74, -146, -146, -218, -289, -289, -361, -433, -433, -504, -576, -647, -719, -719, -719, -791, -863, -863, -863, -863, -863, -791, -719, -648, -576, -361, -74, 211, 355, 785, 1071, 1429, 1788, 2146, 2504, 2791, 3149, 3364, 3436, 3651, 3937, 4152, 4295, 4439, 4439, 4295, 4152, 4081, 3937, 3794, 3794, 3651, 3436, 3221, 3077, 2863, 2719, 2647, 2504, 2433, 2289, 2146, 2146, 2003, 1931, 1788, 1788, 1644, 1644, 1573, 1501, 1429, 1429, 1358, 1358, 1286, 1286, 1214, 1143, 1143, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1071, 1000, 1000, 856, 856, 713, 713, 570, 570, 570, 426, 426, 426, 283, 283, 140, 140, 140, 140, -3, -3, -3, -146, -146, -146, -146, -218, -289, -289, -289, -289, -289, -289, -218, -74, 140, 355, 641, 1000, 1358, 1644, 2074, 2433, 2862, 3221, 3579, 3937, 4224, 4511, 4725, 4797, 4940, 5084, 5227, 5299, 5227, 5155, 5084, 5012, 5012, 4940, 4940, 4797, 4725, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:18<00:00, 18.63s/it]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prediction too short 35 < 96, padded with last value\n",
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'model': 'gpt-4', 'alpha': 0.3, 'basic': True, 'temp': 1.0, 'top_p': 0.8, 'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan'), 'dataset_name': 'exchange_rate'}) \n",
      " with NLL inf\n",
      "warning: input_len 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968, 985, 994, 981, 979, 981, 981, 983, 981, 990, 981, 983, 981, 981, 993, 1004, 1003, 1020, 1001, 1002, 1002, 1005, 1005, 1009, 1018, 1011, 1012, 1012, 1031, 1021, 1038, 1032, 1035, 1033, 1033, 1025, 1018, 996, 1005, 984, 984, 984, 988, 981, 992, 983, 993, 992, 992, 1014, 1014, 1011, 1004, 1016, 1017, 1017, 1022, 1015, 1021, 997, 992, 992, 992, 1005, 990, 998, 978, 972, 971, 971, 976, 996, 991, 989, 980, 981, 980, 975, 972, 975, 998, 991, 990, 990, 997, 988, 988, 972, 970, 974, 974, 969, 960, 965, 964, 966, 966, 966, 970, 983, 987, 993, 990, 990, 990, 1003, 1002, 1006, 1003, 1003, 1008, 1008, 1015, 1014, 1011, 1016, 1010, 1010, 1010, 1011, 1010, 985, 976, 975, 975, 971, 978, 970, 967, 967, 965, 964, 959, 966, 973, 968, 941, 936, 936, 936, 941, 950, 946, 959, 951, 953, 953, 955, 964, 963, 960, 951, 952, 952, 959, 952, 948, 939, 958, 958, 958, 956, 952, 950, 940, 952, 951, 951, 957, 960, 967, 957, 959, 960, 958, 957, 968, 980, 978, 969, 969, 970, 965, 965, 961, 969, 962, 962, 962, 969, 971, 971, 968, 965, 965, 965, 962, 963, 970, 967, 978, 980, 980, 975, 972, 977, 973, 968, 968, 968, 970, 972, 972, 973, 978, 981, 981, 989, 977, 981, 991, 995, 1001, 1001, 1000, 987, 982, 974, 979, 979, 981, 986, 985, 975, 981, 971, 968, 973, 949, 952, 924, 912, 926, 928, 930, 923, 909, 915, 935, 927, 929, 930, 931, 933, 928, 931, 918, 921, 921, 906, 906, 916, 939, 941, 944, 943, 953, 954, 956, 962, 965, 965, 965, 971, 970, 975, 974, 978, 977, 971, 970, 948, 943, 943, 942, 944, 944, 941, 948, 963, 967, 971, 973, 973, 971, 983, 989, 991, 972, 973, 973, 966, 979, 982, 992, 992, 997, 996, 1005, 1001, 998, 992, 991, 993, 994, 1001, 1005, 1004, 996, 997, 1003, 1003, 997, 986, 981, 968, 969, 965, 969, 969, 977, 981, 968, 966, 961, 961, 965, 965, 954, 963, 973, 972, 972, 970, 955, 974, 976, 986, 987, 987, 989, 988, 988, 992, 995, 996, 996, 1003, 1008, 1003, 989, 995, 994, 994, 998, 997, 1007, 1003, 1004, 1005, 1004, 1007, 1013, 1009, 1004, 1018, 1018, 1016, 1014, 1023, 1030, 1024, 1030, 1032, 1032, 1030, 1030, 1043, 1037, 1037, 1034, 1034, 1036, 1024, 1032, 1022, 1021, 1022, 1019, 1029, 1026, 1016, 1031, 1044, 1043, 1043, 1049, 1057, 1061, 1086, 1089, 1089, 1089, 1080, 1078, 1069, 1066, 1062, 1058, 1058, 1063, 1050, 1056, 1063, 1063, 1066, 1066, 1056, 1042, 1043, 1042, 1026, 1026, 1027, 1018, 1019, 1034, 1034, 1043, 1044, 1044, 1039, 1042, 1023, 1020, 1023, 1024, 1024, 1033, 1030, 1019, 1007, 1007, 1007, 1007, 1016, 1018, 1017, 1025, 1025, 1025, 1025, 1023, 1033, 1047, 1052, 1066, 1067, 1067, 1062, 1050, 1042, 1037, 1038, 1040, 1037, 1043, 1040, 1039, 1053, 1051, 1050, 1051, 1058, 1054, 1056, 1035, 1037, 1037, 1037, 1045, 1045, 1048, 1055, 1058, 1057, 1057, 1057, 1068, 1067, 1058, 1052, 1052, 1052, 1054, 1064, 1056, 1050, 1039, 1040, 1040, 1035, 1029, 1029, 1038, 1044, 1045, 1045, 1041, 1024, 1020, 1023, 1028, 1028, 1027, 1028, 1027, 1016, 1013, 1008, 1011, 1008, 1007, 1013, 1012, 1006, 1019, 1010, 1001, 999, 983, 1000, 1000, 1000, 1004, 1013, 1015, 1026, 1026, 1026, 1026, 1032, 1034, 1045, 1046, 1048, 1051, 1050, 1049, 1052, 1066, 1063, 1071, 1072, 1072, 1069, 1075, 1079, 1085, 1092, 1094, 1091, 1080, 1078, 1088, 1098, 1097, 1097, 1098, 1094, 1102, 1102, 1094, 1106, 1105, 1105, 1107, 1095, 1082, 1075, 1085, 1088, 1088, 1086, 1084, 1079, 1092, 1077, 1077, 1074, 1071, 1071, 1079, 1081, 1093, 1086, 1086, 1081, 1090, 1092, 1108, 1119, 1120, 1120, 1119, 1127, 1123, 1117, 1119, 1116, 1116, 1114, 1124, 1117, 1132, 1125, 1127, 1127, 1113, 1121, 1103, 1096, 1110, 1109, 1109, 1108, 1111, 1119, 1109, 1111, 1111, 1111, 1101, 1109, 1127, 1131, 1133, 1132, 1132, 1135, 1133, 1132, 1137, 1142, 1147, 1140, 1135, 1122, 1145, 1154, 1157, 1154, 1154, 1155, 1172, 1171, 1181, 1184, 1183, 1183, 1185, 1193, 1191, 1193, 1201, 1201, 1201, 1197, 1189, 1182, 1155, 1157, 1138, 1138, 1136, 1117, 1119, 1129, 1141, 1138, 1138, 1135, 1143, 1146, 1122, 1123, 1128, 1128, 1129, 1139, 1132, 1135, 1150, 1149, 1155, 1165, 1165, 1159, 1139, 1138, 1139, 1125, 1120, 1130, 1125, 1137, 1122, 1117, 1065, 1066, 1057, 1086, 1066, 1050, 1039, 1043, 1049, 1053, 1074, 1068, 1092, 1083, 1090, 1088, 1086, 1097, 1091, 1085, 1124, 1110, 1086, 1080, 1084, 1083, 1088, 1087, 1075, 1062, 1076, 1066, 1052, 1052, 1043, 1036, 1035, 1022, 1020, 1013, 1015, 1015, 1033, 1043, 1063, 1063, 1064, 1070, 1065, 1058, 1058, 1058, 1058, 1043, 1045, 1028, 1032, 1044, 1036, 1052, 1050, 1060, 1059, 1059, 1056, 1053, 1054, 1068, 1064, 1064, 1066, 1081, 1070, 1069, 1074, 1088, 1087, 1084, 1085, 1086, 1095, 1102, 1109, 1108, 1102, 1124, 1127, 1121, 1129, 1142, 1143, 1144, 1144, 1141, 1144, 1141, 1145, 1134, 1131, 1143, 1139, 1147, 1137, 1139, 1150, 1145, 1135, 1141, 1145, 1144, 1150, 1146, 1150, 1150, 1137, 1134, 1125, 1110, 1122, 1128, 1124, 1124, 1124, 1118, 1125, 1107, 1122, 1129, 1128, 1128, 1131, 1119, 1114, 1107, 1118, 1121, 1121, 1123, 1124, 1117, 1113, 1123, 1120, 1129, 1127, 1115, 1117, 1121, 1117, 1117, 1126, 1115, 1120, 1132, 1128, 1126, 1126, 1124, 1126, 1117, 1113, 1119, 1110, 1113, 1114, 1126, 1118, 1115, 1108, 1094, 1088, 1089, 1089, 1079, 1076, 1077, 1075, 1067, 1055, 1047, 1050, 1030, 1036, 1036, 1043, 1037, 1025, 1027, 1034, 1031, 1041, 1041, 1033, 1032, 1030, 1032, 1034, 1034, 1051, 1055, 1053, 1057, 1061, 1067, 1067, 1078, 1083, 1092, 1089, 1079, 1083, 1082, 1082, 1076, 1083, 1083, 1074, 1098, 1097, 1097, 1100, 1101, 1101, 1100, 1090, 1092, 1090, 1089, 1093, 1081, 1088, 1091, 1092, 1095, 1098, 1093, 1094, 1094, 1079, 1075, 1081, 1097, 1108, 1106, 1109, 1113, 1106, 1120, 1121, 1121, 1124, 1117, 1116, 1110, 1111, 1106, 1103, 1104, 1110, 1105, 1105, 1105, 1107, 1110, 1107, 1114, 1111, 1108, 1100, 1099, 1092, 1099, 1100, 1091, 1086, 1087, 1099, 1111, 1108, 1120, 1121, 1135, 1135, 1130, 1132, 1133, 1132, 1137, 1122, 1130, 1127, 1138, 1136, 1135, 1133, 1121, 1126, 1120, 1120, 1124, 1118, 1116, 1121, 1118, 1118, 1118, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:18<00:00, 18.82s/it]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prediction too short 71 < 96, padded with last value\n",
      "Warning: Prediction too short 77 < 96, padded with last value\n",
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'model': 'gpt-4', 'alpha': 0.3, 'basic': True, 'temp': 1.0, 'top_p': 0.8, 'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan'), 'dataset_name': 'national_illness'}) \n",
      " with NLL inf\n",
      "warning: input_len 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "991, 980, 1225, 1211, 1254, 1255, 1155, 1236, 1223, 987, 1308, 1314, 1276, 1186, 955, 1080, 1337, 1318, 1224, 1268, 1214, 1213, 1187, 1199, 1160, 1124, 1138, 1107, 1104, 1136, 1092, 1101, 1050, 1017, 980, 914, 851, 879, 851, 859, 850, 746, 855, 820, 825, 767, 822, 821, 822, 849, 848, 918, 931, 992, 1344, 1353, 1333, 1380, 1375, 1382, 1366, 1377, 1047, 1344, 1262, 1281, 967, 1070, 1277, 1345, 1237, 1280, 1265, 1222, 1278, 1310, 1244, 1249, 1263, 1266, 1255, 1273, 1216, 1212, 1205, 1160, 1113, 1068, 982, 992, 999, 933, 937, 846, 945, 931, 930, 949, 952, 923, 1000, 1006, 910, 1094, 1095, 1075, 1323, 1303, 1330, 1356, 1345, 1349, 1328, 1307, 1055, 1381, 1342, 1316, 1042, 1092, 1214, 1246, 1258, 1241, 1280, 1294, 1174, 1278, 1242, 1267, 1264, 1260, 1213, 1235, 1259, 1190, 1198, 1177, 1124, 1066, 969, 959, 961, 947, 931, 841, 928, 925, 912, 892, 910, 911, 959, 999, 974, 918, 1024, 1029, 1023, 1271, 1273, 1297, 1275, 1330, 1300, 1318, 1006, 1324, 1295, 1232, 964, 1023, 1238, 1226, 1169, 1301, 1295, 1280, 1283, 1335, 1345, 1334, 1266, 1237, 1221, 1238, 1246, 1220, 1218, 1165, 1142, 1083, 1000, 940, 994, 971, 948, 902, 864, 947, 944, 933, 914, 921, 966, 977, 966, 946, 1048, 1061, 1020, 1341, 1337, 1409, 1394, 1381, 1358, 1375, 1098, 1386, 1332, 1275, 1163, 1103, 1234, 1297, 1329, 1393, 1398, 1418, 1387, 1380, 1374, 1339, 1266, 1368, 1329, 1306, 1261, 1247, 1271, 1228, 1199, 1145, 1064, 970, 1017, 995, 988, 915, 876, 942, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:20<00:00, 20.47s/it]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'model': 'gpt-4', 'alpha': 0.3, 'basic': True, 'temp': 1.0, 'top_p': 0.8, 'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan'), 'dataset_name': 'traffic'}) \n",
      " with NLL inf\n",
      "warning: input_len 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190, 283, 495, 948, 1206, 1578, 1903, 2207, 2475, 2480, 2248, 2176, 2186, 2197, 2016, 1815, 1505, 1340, 1103, 737, 479, 221, 216, 273, 453, 556, 840, 1727, 2186, 2099, 2222, 2661, 2712, 2743, 2702, 3249, 3357, 3305, 2784, 2331, 1732, 1495, 1046, 706, 428, 293, 237, 309, 443, 974, 1629, 2078, 2336, 2258, 2068, 2599, 2851, 2790, 3362, 3388, 3305, 3476, 2862, 2558, 2186, 1640, 1191, 727, 531, 340, 283, 345, 562, 1088, 1531, 2119, 2449, 2140, 2258, 2743, 2810, 2970, 3264, 3408, 3372, 3543, 3094, 2630, 2047, 1727, 1227, 768, 556, 330, 221, 293, 520, 1072, 1542, 2109, 2377, 2227, 2227, 2573, 2996, 2975, 3671, 3733, 3424, 3548, 3078, 2614, 2145, 1815, 1227, 959, 665, 350, 319, 366, 531, 1057, 1521, 2129, 2377, 2413, 2573, 3063, 3264, 3099, 2697, 3759, 3599, 3445, 2903, 2552, 2078, 1722, 1444, 1005, 758, 438, 319, 309, 293, 453, 541, 1077, 1562, 1897, 2305, 2738, 2831, 2748, 2748, 2748, 2692, 2454, 2207, 1903, 1650, 1521, 1376, 1010, 737, 371, 257, 226, 170, 257, 479, 773, 1108, 1438, 1810, 2021, 2346, 2341, 2315, 2233, 2227, 2078, 1954, 1593, 1500, 1397, 1057, 809, 572, 304, 206, 170, 221, 283, 422, 624, 861, 1041, 1449, 1670, 2037, 2150, 1985, 1810, 1583, 1428, 1258, 1232, 1041, 979, 2006, 1083, 608, 314, 195, 309, 458, 794, 1433, 1846, 2062, 2191, 2186, 2594, 2779, 2898, 3491, 3764, 3455, 3563, 3053, 2320, 1820, 1433, 943, 422, 366, 299, 201, 288, 556, 861, 1619, 1970, 2336, 2279, 2274, 2728, 2810, 2805, 3362, 3341, 3630, 3589, 2939, 2614, 2042, 1619, 1041, 933, 515, 309, 226, 232, 489, 917, 1531, 2062, 2233, 2274, 2243, 2681, 2924, 3084, 3553, 3625, 3439, 3537, 3140, 2630, 2104, 1768, 1160, 701, 500, 345, 242, 324, 474, 1010, 1603, 1959, 2140, 2392, 2418, 2826, 3233, 3027, 3919, 3630, 3481, 3470, 3176, 2656, 2186, 1748, 1376, 1062, 665, 464, 273, 288, 314, 469, 799, 1237, 1634, 1897, 2315, 2568, 2882, 2955, 2924, 2934, 2955, 2532, 2521, 1985, 1727, 1624, 1433, 1211, 758, 407, 299, 268, 211, 293, 453, 747, 1052, 1521, 1841, 2294, 2465, 2599, 2403, 2454, 2413, 2197, 2057, 1645, 1464, 1325, 995, 680, 417, 221, 201, 252, 495, 985, 1490, 1877, 2279, 2341, 2181, 2583, 2723, 2810, 3285, 3352, 3331, 3496, 3017, 2269, 1727, 1449, 1041, 691, 469, 232, 221, 330, 479, 1005, 1572, 1980, 2300, 2191, 2202, 2692, 2862, 2800, 3249, 3537, 3331, 3594, 3202, 2563, 2006, 1609, 1062, 804, 500, 314, 283, 242, 531, 979, 1593, 2073, 2320, 2099, 2222, 2594, 2831, 2836, 3465, 3739, 3641, 3367, 3182, 2269, 1841, 1835, 1413, 768, 520, 293, 257, 314, 603, 954, 1614, 2062, 2362, 2418, 2444, 2547, 3011, 3053, 3408, 3615, 3424, 3383, 3084, 2558, 2140, 1866, 1304, 809, 536, 366, 263, 335, 515, 948, 1526, 2150, 2253, 2331, 2501, 2753, 3063, 3207, 3568, 3156, 3439, 3053, 2753, 2181, 2037, 1753, 1376, 892, 577, 386, 283, 252, 304, 407, 887, 1474, 1908, 2011, 2207, 2583, 2790, 2748, 2764, 2774, 2666, 2681, 2779, 2140, 1820, 1779, 1423, 1232, 763, 469, 293, 273, 211, 283, 474, 804, 1165, 1547, 1944, 2243, 2583, 2558, 2403, 2392, 2325, 2300, 2016, 1815, 1603, 1402, 990, 649, 438, 226, 195, 273, 541, 887, 1578, 2006, 2444, 2078, 2104, 2542, 2681, 2831, 3161, 3491, 3341, 3450, 3084, 2346, 1794, 1423, 990, 722, 479, 232, 226, 314, 520, 907, 1516, 2119, 2336, 2068, 2248, 2573, 2862, 2960, 3321, 3460, 3450, 3537, 3047, 2511, 2016, 1701, 1150, 814, 526, 324, 273, 288, 572, 892, 1624, 2062, 2331, 2325, 2238, 2656, 2888, 2831, 3470, 3532, 3568, 3656, 3109, 2650, 2068, 1949, 1093, 840, 526, 330, 252, 319, 598, 1015, 1593, 2057, 2336, 2362, 2372, 2645, 2851, 3001, 3316, 3599, 3651, 3666, 3187, 2578, 2057, 1794, 1289, 804, 556, 381, 263, 299, 515, 985, 1670, 1990, 2248, 2269, 2465, 2898, 3109, 3171, 3635, 3625, 3620, 3651, 3316, 2717, 2181, 1939, 1567, 1098, 778, 484, 304, 314, 340, 505, 773, 1150, 1593, 1980, 2227, 2578, 2784, 2790, 2759, 2748, 2769, 1820, 1397, 1015, 1046, 1010, 902, 675, 526, 304, 165, 216, 206, 319, 422, 752, 1217, 1464, 1805, 2207, 2315, 2392, 2171, 2289, 2233, 2114, 1939, 1691, 1588, 1402, 1000, 742, 417, 278, 273, 324, 458, 954, 1371, 2047, 2181, 2021, 2279, 2496, 2733, 2728, 3084, 3388, 3481, 3429, 2619, 2594, 1727, 1567, 990, 727, 500, 288, 237, 366, 495, 995, 1500, 2052, 2155, 2104, 2279, 2707, 2888, 3001, 3336, 3568, 3630, 3434, 3099, 2408, 2135, 1640, 1217, 783, 546, 371, 304, 273, 603, 995, 1552, 2093, 2294, 2197, 2346, 2516, 2893, 2991, 3140, 3476, 3414, 3532, 2980, 2666, 2114, 1835, 1206, 747, 567, 371, 283, 293, 572, 990, 1583, 2233, 2320, 2140, 2537, 2563, 3006, 3120, 3300, 3522, 3604, 3687, 2552, 2521, 2398, 1779, 1320, 985, 654, 355, 330, 335, 546, 1000, 1603, 2109, 2274, 2248, 2480, 2826, 3161, 3491, 3821, 3728, 3574, 3795, 3264, 2779, 2362, 2031, 1469, 1108, 789, 479, 345, 293, 324, 546, 804, 1124, 1722, 1980, 2243, 2454, 2769, 2975, 2810, 2821, 2888, 2759, 2300, 2145, 2160, 1815, 1495, 1299, 825, 422, 366, 237, 195, 273, 448, 711, 1077, 1454, 1835, 2160, 2604, 2650, 2516, 2578, 2465, 2444, 2197, 1954, 1676, 1387, 1000, 814, 546, 304, 268, 252, 489, 1015, 1474, 1923, 2078, 1918, 2197, 2480, 2594, 3120, 3347, 3393, 3501, 3460, 2980, 2449, 1794, 1423, 1041, 644, 489, 247, 237, 340, 510, 887, 1572, 2362, 2341, 2258, 2171, 2563, 2821, 2934, 3187, 3357, 3635, 3579, 2934, 2738, 1928, 1531, 1062, 737, 464, 314, 268, 293, 531, 902, 1521, 2274, 2346, 2104, 2382, 2656, 3006, 2867, 2934, 2949, 3383, 3192, 2996, 2862, 2160, 1712, 1052, 670, 520, 299, 268, 350, 500, 995, 1588, 2248, 2264, 2099, 2331, 2594, 2898, 3078, 3486, 3424, 3687, 3739, 3073, 2635, 2300, 1645, 1150, 804, 510, 433, 319, 335, 458, 1005, 1614, 2155, 1964, 2274, 2227, 2805, 3047, 3378, 3842, 3837, 3599, 3795, 3238, 2753, 2300, 2021, 1392, 1046, 799, 443, 299, 293, 288, 510, 809, 1191, 1660, 1964, 2398, 2635, 2882, 2919, 2882, 2944, 2805, 2743, 2527, 2233, 2052, 1712, 1366, 1134, 701, 428, 330, 226, 190, 268, 407, 737, 1041, 1449, 1923, 2186, 2408, 2645, 2521, 2465, 2599, 2398, 2088, 1835, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:20<00:00, 20.05s/it]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with best hyper... defaultdict(<class 'dict'>, {'model': 'gpt-4', 'alpha': 0.3, 'basic': True, 'temp': 1.0, 'top_p': 0.8, 'settings': SerializerSettings(base=10, prec=3, signed=True, fixed_length=False, max_val=10000000.0, time_sep=', ', bit_sep='', plus_sign='', minus_sign='-', half_bin_correction=True, decimal_point='', missing_str=' Nan'), 'dataset_name': 'weather'}) \n",
      " with NLL inf\n",
      "warning: input_len 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "987, 986, 984, 985, 987, 987, 987, 986, 996, 1001, 996, 986, 990, 1008, 1015, 1006, 1010, 1007, 1005, 999, 1004, 1032, 1017, 1008, 1010, 1012, 1014, 1023, 1019, 1016, 1028, 1025, 1034, 1033, 1039, 1036, 1034, 1044, 1055, 1064, 1064, 1074, 1075, 1070, 1072, 1067, 1059, 1053, 1057, 1054, 1059, 1080, 1086, 1080, 1077, 1085, 1075, 1078, 1066, 1068, 1073, 1072, 1079, 1082, 1081, 1074, 1072, 1075, 1074, 1075, 1092, 1080, 1078, 1081, 1089, 1099, 1097, 1101, 1099, 1094, 1092, 1086, 1087, 1093, 1084, 1080, 1092, 1099, 1093, 1107, 1103, 1113, 1114, 1108, 1116, 1120, 1124, 1113, 1115, 1120, 1120, 1114, 1095, 1086, 1045, 1027, 1034, 1037, 1035, 1025, 1018, 1020, 1018, 1013, 1013, 1011, 1001, 1001, 1005, 1006, 1007, 1005, 1005, 1000, 998, 999, 996, 996, 996, 997, 1006, 1006, 1006, 1007, 1007, 1005, 1006, 1002, 1001, 998, 993, 988, 989, 990, 990, 993, 996, 997, 997, 993, 990, 991, 993, 992, 992, 994, 1001, 998, 998, 999, 1008, 1016, 1004, 1001, 1000, 999, 1000, 1003, 1005, 1005, 1005, 1005, 1007, 1007, 1007, 1008, 1012, 1016, 1017, 1018, 1020, 1017, 1013, 1011, 1011, 1012, 1011, 1011, 1015, 1015, 1012, 1011, 1009, 1007, 1008, 1006, 1008, 1009, 1008, 1008, 1007, 1007, 1007, 1007, 1006, 1005, 1005, 1006, 1007, 1005, 1006, 1007, 1008, 1008, 1008, 1008, 1007, 1008, 1009, 1009, 1008, 1008, 1009, 1009, 1008, 1007, 1007, 1007, 1007, 1008, 1007, 1007, 1007, 1006, 1005, 1005, 1005, 1005, 1005, 1004, 1003, 1003, 1003, 1003, 1002, 1002, 1001, 1001, 1000, 999, 999, 999, 998, 998, 998, 997, 997, 997, 996, 995, 994, 994, 994, 994, 995, 994, 995, 994, 994, 993, 993, 993, 993, 993, 993, 993, 993, 993, 993, 993, 993, 994, 994, 994, 995, 995, 995, 995, 996, 996, 997, 997, 997, 997, 998, 998, 999, 999, 999, 1000, 1000, 999, 1000, 1000, 1000, 1000, 1000, 1000, 1001, 1001, 1001, 1002, 1002, 1002, 1002, 1002, 1003, 1003, 1003, 1004, 1004, 1003, 1003, 1004, 1004, 1004, 1004, 1004, 1005, 1004, 1004, 1005, 1006, 1005, 1004, 1004, 1004, 1004, 1004, 1004, 1004, 1005, 1004, 1004, 1004, 1005, 1004, 1005, 1005, 1005, 1005, 1008, 1005, 1005, 1005, 1006, 1005, 1005, 1006, 1006, 1006, 1007, 1007, 1008, 1008, 1007, 1007, 1008, 1009, 1009, 1009, 1009, 1009, 1009, 1009, 1008, 1009, 1009, 1011, 1010, 1010, 1010, 1011, 1012, 1011, 1011, 1011, 1011, 1010, 1011, 1011, 1011, 1011, 1010, 1011, 1010, 1008, 1007, 1007, 1007, 1007, 1005, 1005, 1005, 1006, 1005, 1005, 1004, 1003, 1004, 1004, 1004, 1004, 1004, 1004, 1003, 1002, 1003, 1002, 1002, 1001, 1001, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1001, 1001, 1001, 1000, 1001, 1001, 1002, 1001, 1001, 1001, 1000, 1000, 1000, 1001, 1001, 1001, 1002, 1003, 1005, 1004, 1005, 1005, 1004, 1004, 1003, 1005, 1005, 1004, 1003, 1002, 1002, 1001, 1001, 1002, 1002, 1003, 1003, 1003, 1002, 1002, 1003, 1004, 1005, 1006, 1007, 1007, 1006, 1008, 1007, 1006, 1004, 1004, 1003, 1003, 1003, 1003, 1003, 1004, 1004, 1005, 1005, 1006, 1006, 1006, 1006, 1007, 1008, 1009, 1010, 1009, 1009, 1009, 1010, 1010, 1011, 1009, 1010, 1008, 1008, 1007, 1006, 1006, 1006, 1006, 1006, 1006, 1006, 1007, 1006, 1007, 1007, 1007, 1006, 1006, 1007, 1006, 1006, 1005, 1005, 1004, 1003, 1002, 1003, 1004, 1003, 1002, 1001, 1001, 1000, 1000, 1000, 999, 997, 999, 997, 995, 995, 995, 994, 994, 993, 991, 990, 990, 988, 988, 990, 988, 987, 987, 988, 989, 988, 986, 985, 986, 986, 988, 988, 986, 986, 987, 986, 988, 989, 989, 991, 992, 992, 993, 993, 993, 995, 995, 994, 993, 994, 994, 994, 994, 995, 996, 997, 996, 997, 997, 998, 999, 996, 994, 992, 991, 990, 990, 990, 993, 994, 996, 997, 998, 998, 996, 997, 997, 997, 999, 998, 997, 997, 996, 997, 998, 998, 996, 995, 994, 993, 993, 994, 996, 997, 998, 999, 1000, 1000, 1002, 1001, 1000, 1000, 1000, 1000, 999, 998, 999, 999, 1002, 1002, 1002, 1004, 1005, 1006, 1001, 1000, 1000, 1000, 999, 1000, 1000, 1001, 1001, 1002, 1002, 1004, 1008, 1008, 1005, 1006, 1007, 1009, 1007, 1005, 1003, 1002, 1002, 1002, 1001, 1000, 1000, 999, 998, 999, 999, 999, 997, 996, 998, 998, 998, 998, 995, 994, 996, 998, 997, 997, 994, 996, 999, 1000, 998, 997, 997, 997, 996, 999, 1000, 1000, 1000, 1001, 1002, 1001, 1000, 1001, 1002, 1001, 999, 998, 998, 997, 997, 998, 997, 998, 1000, 1000, 1001, 1004, 1003, 1004, 1006, 1008, 1009, 1008, 1007, 1009, 1011, 1012, 1013, 1012, 1011, 1013, 1011, 1010, 1010, 1012, 1011, 1011, 1009, 1011, 1010, 1008, 1010, 1009, 1009, 1005, 1004, 1002, 1004, 1006, 1008, 1009, 1009, 1010, 1010, 1011, 1013, 1013, 1014, 1012, 1018, 1021, 1015, 1015, 1013, 1011, 1010, 1012, 1013, 1015, 1017, 1013, 1012, 1010, 1010, 1010, 1011, 1017, 1016, 1009, 1009, 1009, 1009, 1008, 1008, 1008, 1008, 1008, 1008, 1008, 1009, 1009, 1009, 1009, 1009, 1010, 1010, 1011, 1011, 1010, 1010, 1010, 1008, 1007, 1005, 1004, 1003, 1003, 1003, 1001, 999, 998, 997, 996, 995, 993, 992, 991, 991, 989, 988, 987, 986, 985, 985, 983, 984, 984, 984, 983, 984, 986, 985, 983, 983, 983, 982, 984, 985, 988, 988, 988, 989, 989, 988, 989, 989, 989, 989, 990, 990, 990, 991, 993, 994, 995, 997, 998, 998, 1000, 1001, 1003, 1003, 1003, 1004, 1006, 1006, 1006, 1008, 1007, 1007, 1007, 1009, 1009, 1009, 1010, 1011, 1011, 1012, 1013, 1013, 1014, 1014, 1014, 1015, 1016, 1017, 1019, 1018, 1019, 1023, 1024, 1020, 1019, 1020, 1022, 1023, 1021, 1021, 1022, 1025, 1027, 1032, 1031, 1029, 1029, 1032, 1036, 1038, 1041, 1040, 1042, 1042, 1042, 1046, 1047, 1048, 1050, 1050, 1051, 1053, 1056, 1056, 1054, 1056, 1065, 1067, 1064, 1067, 1078, 1062, 1066, 1071, 1076, 1080, 1075, 1077, 1080, 1092, 1086, 1086, 1090, 1089, 1090, 1087, 1087, 1089, 1095, 1089, 1078, 1075, 1068, 1062, 1058, 1055, 1053, 1052, 1046, 1043, 1037, 1036, 1032, 1030, 1030, 1029, 1023, 1015, 1019, 1017, 1008, 1007, 1011, 1010, 1005, 1005, 1002, 996, 987, 986, 985, 984, 983, 985, 984, 984, 982, 982, 983, 983, 983, 983, 982, 983, 985, 987, 988, 987, 989, 992, 990, 991, 990, 992, 994, 995, 995, 997, 997, 998, 1007, 1005, 1010, 1011, 1008, 1007, 1010, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:19<00:00, 19.21s/it]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "pred_dict_list = []\n",
    "\n",
    "for name, dataset in datasets_tmp.items():\n",
    "    def metrics_computation(test, median_pred):\n",
    "        mse = mean_squared_error(test, median_pred)\n",
    "        mae = mean_absolute_error(test, median_pred)\n",
    "        mape = mean_absolute_percentage_error(test, median_pred) * 100\n",
    "        r2 = r2_score(test, median_pred)        \n",
    "        return mse, mae, mape, r2\n",
    "        \n",
    "    train, test = dataset \n",
    "    train = train[len(train)-1024:]['OT']  # We here cutoff 1024 numbers for the training set (in terms of context length)\n",
    "    test = test[:96]['OT']  # next 96 numbers\n",
    "    \n",
    "    for model in model_names: \n",
    "        model_hypers[model].update({'dataset_name': name})  # for promptcast, dict 添加元素\n",
    "        hypers = list(grid_iter(model_hypers[model]))  # 简单理解为传参\n",
    "        num_samples = 10  # 表示重复的预测的次数, 原本需要为10, 此处暂时选择 2 来进行测试\n",
    "        pred_dict = get_autotuned_predictions_data(train, test, hypers, num_samples, model_predict_fns[model], verbose=False, parallel=False, whether_blanket=False) \n",
    "        pred_dict_list.append(pred_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
